{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccddbac",
   "metadata": {},
   "source": [
    "# Qkeras Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d3b6e",
   "metadata": {},
   "source": [
    "## Section 1: Preparation before quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b5101",
   "metadata": {},
   "source": [
    "### 1.1: Please run the following cell to check if your qkeras and other needed packages are installed and import correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c6a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qkeras\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, LSTM, Masking, Input, GRU, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a71046",
   "metadata": {},
   "source": [
    "### The following three sections in our tutorial is corresponding to three different ways for doing quantization in Qkeras: Post Training Quantization, Quantization Aware Training, and Auto Qkeras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e54cd",
   "metadata": {},
   "source": [
    "## Section 2:  Post-training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217f2aa",
   "metadata": {},
   "source": [
    "### 2.1: What is Post-training Quantization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99286155",
   "metadata": {},
   "source": [
    "### Post-training Quantization is a kind of efficient model compression technique, which can directly quantize neural network models after training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e6d52",
   "metadata": {},
   "source": [
    "### 2.2: How to do Post-training quantization with qkeras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673829f",
   "metadata": {},
   "source": [
    "### First, we need to have a already-trainined keras model. You can download a toy model from this github page: https://github.com/uw-acme/HLS4ML_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e3d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 20:52:10.819928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-12 20:52:10.822024: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-12 20:52:10.824587: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-CHSBCRQ): /proc/driver/nvidia/version does not exist\n",
      "2022-10-12 20:52:10.847798: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load the toy model\n",
    "toy_lstm = load_model('hls-rnn-btag/new_lstm/model_lstm_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aeb6da",
   "metadata": {},
   "source": [
    "### The toy model we are using is an b-tag model with one LSTM layer.\n",
    "### Before starting your quantization you need to know what your model looks like. \n",
    "### model.summary() is a great method in keras that you will use frequently to check the layers in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06191194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 15, 6)]           0         \n",
      "                                                                 \n",
      " lstm1 (LSTM)                (None, 120)               60960     \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 50)                6050      \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " relu_1 (Activation)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 3)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,553\n",
      "Trainable params: 67,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A demonstration of what our toy model looks like\n",
    "\n",
    "def lstmmodel(max_len, n_var, rec_units, ndense=[10], l1_reg=0,\n",
    "              l2_reg=0, rec_act='sigmoid', extra_lab='none', rec_kernel_init='VarianceScaling',\n",
    "             dense_kernel_init='lecun_uniform', domask=False):\n",
    "    \n",
    "    hidden = x_in = Input(shape=(max_len, n_var,))\n",
    "    hidden = LSTM(units=rec_units,\n",
    "                  recurrent_activation = rec_act,\n",
    "                  kernel_initializer = rec_kernel_init, \n",
    "                  name = 'lstm1')(hidden)\n",
    "    hidden = Dense(50, kernel_initializer=dense_kernel_init, name='dense_0' )(hidden)\n",
    "    hidden = Activation('relu', name = 'relu_0')(hidden)\n",
    "    hidden = Dense(10, kernel_initializer=dense_kernel_init, name='dense_1' )(hidden)\n",
    "    hidden = Activation('relu', name = 'relu_1')(hidden)\n",
    "    hidden = Dense(3, kernel_initializer=dense_kernel_init, name='dense_2' )(hidden)\n",
    "    hidden = Activation('softmax', name='output_softmax')(hidden)\n",
    "    model = Model(inputs=x_in, outputs=hidden)\n",
    "    \n",
    "    return model\n",
    "\n",
    "l1_reg = 0\n",
    "l2_reg = 0\n",
    "model = lstmmodel(15, 6, 120, [50, 10], l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca13621",
   "metadata": {},
   "source": [
    "### Then we need to check the weight of our toy model before quantization. This is one of the most important steps in quantization for checking if you quantized your model correctly. I highly suggest you to not skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "848fa29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 : []\n",
      "lstm1 : [array([[-0.58963495, -0.65306294,  0.50985825, ...,  1.0137032 ,\n",
      "         0.02196546,  0.15770978],\n",
      "       [-0.15424801,  0.57628304, -0.36964563, ..., -0.09466681,\n",
      "         0.41260427, -0.08563282],\n",
      "       [ 0.18494439, -0.03675471, -0.79524565, ...,  0.47767442,\n",
      "        -0.09714114,  0.3135381 ],\n",
      "       [-0.14735329,  0.6082327 , -0.61543125, ...,  0.26261836,\n",
      "         0.08817887, -0.37429032],\n",
      "       [ 0.34194303, -0.09358562,  0.01487087, ..., -0.5444205 ,\n",
      "         0.01626718,  0.95701003],\n",
      "       [-0.33648208, -0.5004817 , -0.34336048, ...,  0.1277528 ,\n",
      "        -0.03531963,  0.3862824 ]], dtype=float32), array([[ 0.17079291,  0.15018411,  0.07714663, ..., -0.11801086,\n",
      "        -0.07126733, -0.20896389],\n",
      "       [ 0.00498595,  0.14601009, -0.00364938, ..., -0.19730644,\n",
      "        -0.21843092, -0.11314441],\n",
      "       [ 0.04462222,  0.07113124,  0.03417065, ...,  0.01916615,\n",
      "        -0.07676554,  0.03190433],\n",
      "       ...,\n",
      "       [-0.17137632, -0.00948324,  0.07338994, ...,  0.02472536,\n",
      "         0.06145884,  0.00142485],\n",
      "       [-0.0111778 , -0.24703205, -0.02720682, ..., -0.10012444,\n",
      "         0.22103667,  0.1322071 ],\n",
      "       [-0.00476007,  0.07638622, -0.03947302, ..., -0.05086765,\n",
      "        -0.27901876, -0.3069933 ]], dtype=float32), array([-4.08395715e-02,  3.29085499e-01,  7.99515024e-02,  2.47649133e-01,\n",
      "       -4.14236709e-02,  8.77334923e-02,  1.60992108e-02,  2.16326714e-01,\n",
      "        8.13182443e-02, -1.29438825e-02,  3.99061032e-02,  1.37899339e-01,\n",
      "        1.39520004e-01,  2.37001389e-01,  8.27853456e-02,  2.01969333e-02,\n",
      "        1.23544961e-01,  4.98352274e-02,  1.30016461e-01,  5.96405044e-02,\n",
      "        1.47506177e-01,  1.38216704e-01,  3.69921140e-02,  8.16934556e-02,\n",
      "        9.95276682e-03,  1.61841020e-01,  4.08012345e-02,  4.51062918e-02,\n",
      "        1.19680747e-01,  2.26403520e-01,  2.04331756e-01, -1.03174239e-01,\n",
      "        7.84952790e-02,  1.54696195e-03,  1.02930300e-01,  6.45327717e-02,\n",
      "        2.46072002e-02,  1.06687211e-01,  7.29864910e-02,  2.07116306e-01,\n",
      "        7.51569793e-02,  1.80369571e-01,  1.58880278e-01,  2.61691697e-02,\n",
      "        7.03631639e-02,  7.54900798e-02, -6.05555549e-02,  9.32203531e-02,\n",
      "        1.94588974e-01,  3.88387069e-02, -9.85087361e-03,  1.65495470e-01,\n",
      "        1.15146600e-01,  2.00980064e-02,  4.91450280e-02,  7.13688731e-02,\n",
      "       -3.59587148e-02,  3.02149039e-02,  6.92893043e-02,  2.21023280e-02,\n",
      "        1.02065481e-01,  5.32590039e-02,  9.77640226e-02,  6.51191175e-02,\n",
      "        6.94102235e-03, -1.71532091e-02, -8.57593864e-02,  2.79818237e-01,\n",
      "        8.40364676e-03,  1.20180644e-01,  9.97626632e-02,  4.71253246e-02,\n",
      "        1.01957545e-01, -2.07683057e-01, -2.10058000e-02, -7.89543428e-03,\n",
      "        1.03439605e-02, -1.31679550e-02,  8.82523283e-02,  7.78878778e-02,\n",
      "        1.50880506e-02,  1.22214489e-01,  9.09163505e-02,  1.80264220e-01,\n",
      "       -8.14026222e-02,  6.82030469e-02,  2.23284811e-02,  5.18175364e-02,\n",
      "       -5.08963466e-02,  7.98747465e-02,  2.71953583e-01, -1.70888361e-02,\n",
      "        2.37926811e-01,  4.87026274e-02,  7.93503672e-02,  1.75017998e-01,\n",
      "       -3.63117941e-02,  2.08407536e-01, -3.95525582e-02,  6.82084635e-02,\n",
      "        1.07995160e-01,  4.72215340e-02,  1.83345333e-01,  4.85123366e-01,\n",
      "        5.75948097e-02,  4.97602075e-02,  3.36051756e-03,  1.18536502e-01,\n",
      "        6.20269403e-02,  1.21054433e-01, -5.74975051e-02,  3.06905389e-01,\n",
      "       -2.19213925e-02, -7.89254531e-03, -9.36178565e-02, -4.82511297e-02,\n",
      "        2.12002378e-02,  1.61934465e-01,  3.18163261e-02,  1.44649491e-01,\n",
      "        1.06184685e+00,  1.05761492e+00,  1.04581594e+00,  1.02863002e+00,\n",
      "        1.09140742e+00,  1.01714957e+00,  1.02916217e+00,  9.43421364e-01,\n",
      "        1.02683246e+00,  9.12808120e-01,  1.04957664e+00,  1.07617640e+00,\n",
      "        1.17545879e+00,  1.16308725e+00,  1.15642285e+00,  1.11044466e+00,\n",
      "        1.09919798e+00,  1.11645269e+00,  1.06583607e+00,  1.08573711e+00,\n",
      "        9.52187538e-01,  1.07229900e+00,  1.09084487e+00,  1.08001590e+00,\n",
      "        1.11272323e+00,  1.03684127e+00,  1.07875824e+00,  1.03746307e+00,\n",
      "        1.11649382e+00,  1.24766743e+00,  1.11938703e+00,  1.06250358e+00,\n",
      "        1.10163331e+00,  1.02663970e+00,  9.89394724e-01,  1.03615773e+00,\n",
      "        1.10883951e+00,  1.05061150e+00,  1.00340998e+00,  1.06610429e+00,\n",
      "        1.05924678e+00,  9.08307493e-01,  1.04529464e+00,  9.77737367e-01,\n",
      "        1.09305477e+00,  9.24529850e-01,  1.02205443e+00,  1.07344019e+00,\n",
      "        1.06975031e+00,  1.12221527e+00,  9.82131183e-01,  1.09345901e+00,\n",
      "        9.32846904e-01,  1.04805911e+00,  1.01421928e+00,  1.02111030e+00,\n",
      "        1.03932083e+00,  9.73584771e-01,  1.04881573e+00,  1.10688579e+00,\n",
      "        1.02504396e+00,  1.05872822e+00,  1.00636232e+00,  9.70648468e-01,\n",
      "        1.05911255e+00,  1.05877662e+00,  1.03644001e+00,  1.04627562e+00,\n",
      "        1.07167053e+00,  1.08158326e+00,  1.08855820e+00,  1.05649567e+00,\n",
      "        9.87829089e-01,  1.03529859e+00,  1.06319058e+00,  1.03782058e+00,\n",
      "        1.04326785e+00,  9.50756133e-01,  1.02451789e+00,  1.06985831e+00,\n",
      "        1.01883280e+00,  9.91216540e-01,  1.08164489e+00,  9.79674160e-01,\n",
      "        1.08602154e+00,  9.17417824e-01,  9.88841951e-01,  1.10979640e+00,\n",
      "        1.04723847e+00,  1.10552251e+00,  9.96368229e-01,  9.39456344e-01,\n",
      "        1.04260468e+00,  1.02554774e+00,  9.61841881e-01,  1.03219545e+00,\n",
      "        1.06659162e+00,  1.12393749e+00,  1.02604496e+00,  9.77055073e-01,\n",
      "        1.02817631e+00,  1.11780000e+00,  9.82972860e-01,  1.02065837e+00,\n",
      "        1.02246630e+00,  1.07025361e+00,  1.08694196e+00,  1.00051463e+00,\n",
      "        1.11944687e+00,  1.02953124e+00,  1.07918036e+00,  9.77118790e-01,\n",
      "        1.03983223e+00,  1.05759192e+00,  1.01733792e+00,  9.83473003e-01,\n",
      "        1.07533145e+00,  1.05756915e+00,  1.10911679e+00,  1.09849608e+00,\n",
      "       -4.12549600e-02, -2.36714423e-01, -7.40034953e-02,  1.73992366e-01,\n",
      "       -7.31308805e-03,  1.41003847e-01,  6.83594670e-04, -6.25326484e-02,\n",
      "        4.07063439e-02, -4.44049612e-02,  1.27358735e-01,  1.36223465e-01,\n",
      "       -2.50793844e-02, -5.46365827e-02,  1.69378407e-02, -3.50662954e-02,\n",
      "        3.98883708e-02, -8.66903141e-02,  1.27866846e-02,  1.49441302e-01,\n",
      "        1.80881228e-02, -2.40464769e-02,  4.57121199e-03, -1.16935551e-01,\n",
      "        2.68338225e-03,  2.13194042e-01,  1.04150116e-01, -4.58185412e-02,\n",
      "        1.69762835e-01,  2.58342385e-01, -4.49165516e-02,  1.46630928e-01,\n",
      "        2.58921329e-02,  1.00955684e-02,  7.86721185e-02,  7.80657977e-02,\n",
      "       -1.09572401e-02,  5.80030270e-02, -1.99043099e-02,  8.86975154e-02,\n",
      "        1.37628140e-02, -2.79089250e-02,  2.02244315e-02, -3.32996137e-02,\n",
      "       -6.59458935e-02, -5.43610603e-02, -3.00603136e-02, -1.29311398e-01,\n",
      "       -2.56401263e-02, -1.45391868e-02, -6.88332617e-02, -6.91684112e-02,\n",
      "        1.80137660e-02, -2.24772543e-02, -9.76129323e-02, -4.60351594e-02,\n",
      "        5.40405628e-04,  8.92970413e-02, -1.84642486e-02, -3.17717413e-03,\n",
      "       -1.63734540e-01,  2.23292541e-02,  1.29535040e-02,  2.23539155e-02,\n",
      "       -4.81598824e-02, -3.98889408e-02, -6.71864450e-02,  1.81018524e-02,\n",
      "        2.28873845e-02,  1.16627313e-01,  3.93260159e-02, -9.59061980e-02,\n",
      "       -4.93074842e-02, -2.20521390e-02,  7.35467076e-02, -7.24125877e-02,\n",
      "        4.71574403e-02, -8.54906514e-02, -3.50552909e-02, -3.64827216e-02,\n",
      "       -5.46885654e-02, -6.22829422e-02,  6.68430934e-03, -1.31419390e-01,\n",
      "       -6.68089241e-02, -3.69381160e-02,  3.14120762e-02,  6.64427876e-02,\n",
      "        3.72674875e-03, -7.69258812e-02,  1.35750240e-02, -6.81734011e-02,\n",
      "       -4.17093560e-02, -6.58752490e-03, -1.17687009e-01, -1.09128794e-02,\n",
      "       -3.18078548e-02, -1.70686051e-01, -6.58819336e-05, -3.96867692e-02,\n",
      "        5.31962961e-02, -4.44178842e-02, -9.81270596e-02,  9.56261456e-02,\n",
      "        1.08305946e-01,  1.60512757e-02, -9.89453495e-02, -2.07160667e-01,\n",
      "       -5.49988933e-02, -1.28274662e-02, -4.41693887e-02,  7.53551498e-02,\n",
      "        3.46808173e-02,  4.60563414e-03, -7.38264155e-03,  4.53913584e-03,\n",
      "        7.60746524e-02, -4.64217039e-03,  2.93647163e-02, -3.60927939e-01,\n",
      "        1.26230508e-01,  1.36430189e-01,  1.35917708e-01,  4.92402941e-01,\n",
      "        9.07092169e-02,  1.12910435e-01,  7.31509328e-02,  5.41812301e-01,\n",
      "        5.23919314e-02,  1.11350857e-01,  8.32111537e-02,  2.16083467e-01,\n",
      "        2.74995774e-01,  1.71925172e-01,  1.09324127e-01,  2.24330291e-01,\n",
      "        1.68895379e-01,  1.33736998e-01,  1.05274126e-01,  1.56683907e-01,\n",
      "        1.21132925e-01,  1.27017304e-01,  8.76905248e-02,  2.28841349e-01,\n",
      "        6.87110946e-02,  2.71552533e-01,  8.54222551e-02,  9.85532030e-02,\n",
      "        6.21280372e-02,  2.42204905e-01,  1.68402299e-01,  1.84313923e-01,\n",
      "        1.18953586e-01,  1.10975072e-01,  1.25727251e-01,  5.88087216e-02,\n",
      "        7.96934441e-02,  2.09849834e-01,  6.19007349e-02,  5.09027541e-02,\n",
      "        1.06905095e-01,  1.37880534e-01,  2.59461910e-01,  2.03246728e-01,\n",
      "        6.14453219e-02,  1.83073610e-01,  1.09264329e-01,  2.38656282e-01,\n",
      "        2.46290967e-01,  9.75720137e-02,  3.11075728e-02,  1.48977965e-01,\n",
      "        1.09078340e-01,  1.64282277e-01,  7.78544620e-02,  1.84351414e-01,\n",
      "        9.43304747e-02,  1.23011298e-01,  7.82357529e-02,  3.65190618e-02,\n",
      "        1.30547836e-01,  2.16031726e-03,  1.38600484e-01,  2.32503131e-01,\n",
      "        7.55684823e-02,  2.89377905e-02,  8.14698115e-02,  3.53223115e-01,\n",
      "        9.63760167e-02,  1.41375467e-01,  1.10950977e-01,  1.94726363e-01,\n",
      "        7.11402074e-02,  9.42942947e-02,  8.18291232e-02,  5.06099463e-02,\n",
      "        9.11694020e-02,  2.12159380e-02,  6.24809377e-02,  7.56579414e-02,\n",
      "        7.45142400e-02,  8.97801220e-02,  1.53264970e-01,  1.45794630e-01,\n",
      "        2.32621342e-01,  1.71791613e-01,  1.13312460e-01,  1.05411239e-01,\n",
      "        5.74030206e-02,  1.25997394e-01,  1.42372027e-01,  2.77713716e-01,\n",
      "        2.58106679e-01,  1.28285423e-01,  1.16998672e-01,  1.10930622e-01,\n",
      "        3.72661948e-02,  2.86500305e-01,  7.85752684e-02,  3.71410213e-02,\n",
      "        1.19578727e-01,  5.02994023e-02,  8.65860954e-02,  1.57712117e-01,\n",
      "        1.35858625e-01,  1.16351433e-01,  1.25764921e-01,  2.55033463e-01,\n",
      "        1.39454111e-01,  6.53142482e-02,  6.12420104e-02,  1.80524185e-01,\n",
      "        2.65844256e-01,  4.88776229e-02,  1.40775189e-01,  3.33551094e-02,\n",
      "        9.11332890e-02,  1.85773000e-01,  1.17208153e-01,  2.96801031e-01],\n",
      "      dtype=float32)]\n",
      "dense_0 : [array([[ 0.22916724,  0.15485603,  0.35319656, ...,  0.10147922,\n",
      "        -0.20901062, -0.10361186],\n",
      "       [ 0.04625458, -0.07429298, -0.10973423, ...,  0.11775233,\n",
      "         0.07465131, -0.02493156],\n",
      "       [ 0.0238312 , -0.06785677, -0.00823245, ..., -0.1404992 ,\n",
      "        -0.11309165, -0.10411388],\n",
      "       ...,\n",
      "       [ 0.15473719, -0.08815856, -0.16925955, ...,  0.07159934,\n",
      "        -0.1217111 ,  0.22991973],\n",
      "       [-0.06792092, -0.09141374,  0.09193727, ...,  0.14606163,\n",
      "        -0.03054529, -0.1926402 ],\n",
      "       [ 0.07944073, -0.01402885, -0.11033212, ..., -0.07615145,\n",
      "        -0.03951259,  0.01571292]], dtype=float32), array([-0.02590825, -0.00853362, -0.03178774,  0.02928097, -0.00015699,\n",
      "        0.02717862, -0.0292426 , -0.03825049,  0.0093433 , -0.01993226,\n",
      "       -0.05822372,  0.03063643, -0.03733889,  0.04076716, -0.04212371,\n",
      "        0.04145817,  0.01911875, -0.01618677,  0.01367716,  0.00621604,\n",
      "        0.01237447,  0.00202386,  0.00581967,  0.02762854,  0.01706534,\n",
      "        0.00910196, -0.04590155, -0.006064  ,  0.01095249, -0.01916167,\n",
      "       -0.0295264 ,  0.00499911,  0.02894462, -0.02940956, -0.06019126,\n",
      "        0.00837717,  0.06192968,  0.02958142,  0.00635693,  0.039849  ,\n",
      "        0.02193823, -0.01377652,  0.03515537, -0.02518519,  0.07223741,\n",
      "        0.04993482, -0.02687074,  0.00525158,  0.05775007, -0.03566224],\n",
      "      dtype=float32)]\n",
      "relu_0 : []\n",
      "dense_1 : [array([[-1.51369378e-01, -7.40310550e-02, -7.15933219e-02,\n",
      "        -3.66686553e-01, -1.29981026e-01, -3.62496972e-01,\n",
      "        -3.77531946e-01,  5.75192794e-02, -7.30002159e-03,\n",
      "         1.22441873e-01],\n",
      "       [ 5.27407825e-02,  3.57908607e-01,  1.12892769e-01,\n",
      "         8.16985741e-02, -2.48555109e-01, -2.06156552e-01,\n",
      "         1.54499099e-01, -4.21495736e-01, -2.03898787e-01,\n",
      "        -5.07061258e-02],\n",
      "       [ 2.17612237e-01, -3.76612216e-01, -1.31659195e-01,\n",
      "         2.75070637e-01, -1.27245322e-01,  2.67331481e-01,\n",
      "         1.53742254e-01,  8.64181519e-02,  6.47921953e-03,\n",
      "         1.21701866e-01],\n",
      "       [-1.26058877e-01, -1.40585760e-02,  8.27979296e-02,\n",
      "         7.21832886e-02, -1.87897310e-01, -6.34642616e-02,\n",
      "         3.15683573e-01,  2.34946515e-02,  1.31203473e-01,\n",
      "         2.28120938e-01],\n",
      "       [-6.45635054e-02,  1.24262445e-01,  1.75050080e-01,\n",
      "        -2.64563318e-02, -1.91264793e-01, -1.13475531e-01,\n",
      "        -1.15864329e-01,  7.68717825e-02, -5.18980846e-02,\n",
      "         1.21519171e-01],\n",
      "       [ 1.61694065e-01,  1.03483878e-01,  4.37707156e-02,\n",
      "         9.08371955e-02,  1.02975607e-01,  2.78146595e-01,\n",
      "         1.39031410e-01, -2.91117489e-01, -1.66893229e-01,\n",
      "         2.23431438e-01],\n",
      "       [ 6.49913354e-03, -7.10324943e-01, -2.06709892e-01,\n",
      "         2.12076440e-01,  1.86993048e-01,  6.91460371e-01,\n",
      "        -1.46005973e-01, -8.23562674e-04,  1.07760561e+00,\n",
      "         4.63066280e-01],\n",
      "       [ 3.75372708e-01,  2.75686234e-01, -2.29225993e-01,\n",
      "        -1.63952187e-01, -4.41640466e-02, -2.27848172e-01,\n",
      "        -8.63210559e-02,  1.22330479e-01, -2.82589883e-01,\n",
      "        -4.38341767e-01],\n",
      "       [-3.19510579e-01, -1.85610309e-01, -3.46316189e-01,\n",
      "         3.09829682e-01,  1.48762539e-01,  2.60128081e-01,\n",
      "         3.02072346e-01, -3.00321311e-01,  3.76933664e-02,\n",
      "        -9.26816911e-02],\n",
      "       [-6.44758567e-02,  1.58018321e-01, -2.96449184e-01,\n",
      "         2.72980034e-01,  1.59042865e-01, -7.76285231e-02,\n",
      "        -2.17809994e-02, -6.38865829e-02, -2.35492304e-01,\n",
      "        -1.70669615e-01],\n",
      "       [ 6.24553084e-01,  6.79854333e-01, -7.11464509e-02,\n",
      "         4.04078923e-02,  1.91419706e-01, -3.28013211e-01,\n",
      "         1.51773058e-02,  3.39158699e-02, -1.64449811e-01,\n",
      "        -4.39117223e-01],\n",
      "       [-3.78441632e-01, -1.63011923e-01,  1.40149683e-01,\n",
      "         8.99378955e-02, -2.04048857e-01,  1.70485582e-02,\n",
      "        -2.74185240e-01, -6.34222701e-02, -1.45723641e-01,\n",
      "         2.26421848e-01],\n",
      "       [-6.82237148e-02, -3.42524320e-01,  4.42434043e-01,\n",
      "        -3.65321517e-01,  1.14518754e-01,  4.59398404e-02,\n",
      "         4.50085066e-02, -1.22178651e-01, -3.30044031e-02,\n",
      "         2.31786713e-01],\n",
      "       [-2.13357672e-01,  2.14851350e-01,  1.96816936e-01,\n",
      "         1.21358939e-01, -9.67893153e-02, -1.59017429e-01,\n",
      "        -1.46545425e-01, -3.09630055e-02, -4.84576300e-02,\n",
      "        -4.96433489e-03],\n",
      "       [ 1.35211945e-01,  4.27419811e-01,  3.72498453e-01,\n",
      "        -2.12979317e-01,  1.59043834e-01, -2.52288759e-01,\n",
      "        -2.47437749e-02, -1.55269727e-01, -6.58162460e-02,\n",
      "        -8.68024826e-02],\n",
      "       [-2.23043486e-01, -1.34416193e-01, -6.54532239e-02,\n",
      "         2.60836810e-01,  2.97738216e-03,  7.43532255e-02,\n",
      "        -1.81906223e-01,  7.07239062e-02,  2.14341745e-01,\n",
      "        -1.96664948e-02],\n",
      "       [ 1.57626063e-01, -1.44316927e-02, -8.78602490e-02,\n",
      "         1.60636529e-01, -1.89752385e-01,  2.23871186e-01,\n",
      "        -3.61369848e-02, -1.00890666e-01, -9.98358056e-02,\n",
      "        -5.38604073e-02],\n",
      "       [ 1.49234384e-01,  6.11481667e-01, -2.55966932e-01,\n",
      "         5.65880835e-02,  1.25485122e-01, -3.20842266e-01,\n",
      "         3.64574701e-01,  2.11510003e-01, -5.37135601e-01,\n",
      "        -2.62041867e-01],\n",
      "       [ 2.58190066e-01,  2.01820776e-01,  4.71752174e-02,\n",
      "         2.87221242e-02,  1.54200457e-02, -6.06045276e-02,\n",
      "        -3.36020499e-01,  1.78834751e-01, -1.07081942e-01,\n",
      "         1.84164166e-01],\n",
      "       [-1.22706220e-01, -3.35170515e-03,  9.57558490e-03,\n",
      "         2.08684981e-01, -1.43691599e-01, -1.04683854e-01,\n",
      "        -1.16467923e-01,  3.34966838e-01,  2.84190446e-01,\n",
      "        -8.19024742e-02],\n",
      "       [ 3.53401959e-01,  1.72027703e-02,  3.52996111e-01,\n",
      "        -2.84397364e-01,  8.68323222e-02, -1.22956529e-01,\n",
      "        -3.54038835e-01, -3.01290423e-01, -5.01207292e-01,\n",
      "         1.13595746e-01],\n",
      "       [-3.91190708e-01, -1.46313645e-02,  3.12416196e-01,\n",
      "        -1.76669031e-01,  9.43648070e-02, -1.80636927e-01,\n",
      "        -1.96379066e-01, -2.85658780e-02, -7.91240036e-02,\n",
      "         3.91435474e-01],\n",
      "       [ 7.31957033e-02,  1.07502259e-01, -2.87441730e-01,\n",
      "        -6.47895560e-02,  2.10109383e-01,  3.23185444e-01,\n",
      "         9.80144273e-03, -2.90111542e-01,  2.98935771e-02,\n",
      "        -3.01781774e-01],\n",
      "       [ 2.47221254e-02,  1.33820802e-01,  2.15818342e-02,\n",
      "         1.08361952e-02, -6.04657121e-02, -8.65883157e-02,\n",
      "         1.01901861e-02,  7.34814107e-02,  2.14185938e-01,\n",
      "         1.94536790e-01],\n",
      "       [ 2.73530096e-01, -4.03881997e-01, -3.10294062e-01,\n",
      "         3.07938576e-01, -2.37935126e-01,  3.56656134e-01,\n",
      "        -7.40435049e-02,  6.65246844e-02,  4.53848630e-01,\n",
      "         8.94530490e-02],\n",
      "       [-1.20634668e-01, -8.25068355e-02,  1.38039783e-01,\n",
      "         1.97650701e-01, -1.76013812e-01, -5.22449501e-02,\n",
      "         1.80236697e-01,  2.91733414e-01,  2.31184617e-01,\n",
      "        -2.40520716e-01],\n",
      "       [-8.12905356e-02,  6.44402504e-01,  2.30716363e-01,\n",
      "         7.37502724e-02, -1.52371362e-01, -2.29904979e-01,\n",
      "         1.49400502e-01, -3.79576045e-03, -1.82029471e-01,\n",
      "        -2.25202367e-01],\n",
      "       [ 1.40135527e-01,  3.67938399e-01,  4.15888913e-02,\n",
      "         1.38168707e-01,  1.53368041e-01, -7.01789856e-02,\n",
      "        -7.33266324e-02, -2.24886000e-01,  2.91589290e-01,\n",
      "        -1.42408565e-01],\n",
      "       [-7.51841962e-02,  9.76747647e-02,  2.15708926e-01,\n",
      "        -2.81645477e-01, -1.02008484e-01, -2.07767971e-02,\n",
      "        -2.78144002e-01,  8.90610367e-02, -2.26736397e-01,\n",
      "        -1.16353624e-01],\n",
      "       [-2.38238513e-01,  4.48579967e-01,  2.54981190e-01,\n",
      "         2.14056209e-01, -1.67375192e-01,  8.91877487e-02,\n",
      "        -7.48062283e-02, -8.23571980e-02, -2.53043532e-01,\n",
      "        -6.21530302e-02],\n",
      "       [-2.63995361e-02,  6.75723255e-01,  2.72639006e-01,\n",
      "        -2.44866312e-02,  8.83720443e-02,  8.14126059e-02,\n",
      "         2.56282449e-01, -1.19921174e-02, -2.10132465e-01,\n",
      "        -1.72185093e-01],\n",
      "       [-1.97459728e-01,  2.09730789e-01,  1.86732113e-01,\n",
      "         1.94436342e-01, -1.86337516e-01, -8.03731158e-02,\n",
      "         4.69145551e-02,  2.25511909e-01, -2.72601634e-01,\n",
      "         1.25855893e-01],\n",
      "       [-1.41312554e-01,  2.06856444e-01,  1.28295064e-01,\n",
      "        -1.69285908e-01, -9.68017504e-02, -1.22744903e-01,\n",
      "         1.32374153e-01,  9.23676640e-02, -2.22782373e-01,\n",
      "        -2.60288324e-02],\n",
      "       [-1.02118060e-01, -3.33602250e-01,  1.72956929e-01,\n",
      "        -2.53245607e-02,  2.25063730e-02, -2.01722518e-01,\n",
      "         7.29539469e-02,  4.02337909e-02, -1.28008768e-01,\n",
      "         3.23589325e-01],\n",
      "       [ 1.80376738e-01, -4.57271218e-01, -5.72588295e-02,\n",
      "        -9.45651978e-02, -3.25979316e-03, -2.48691499e-01,\n",
      "        -1.44031316e-01,  2.33102918e-01, -8.75592325e-03,\n",
      "         2.55016863e-01],\n",
      "       [-1.93976223e-01, -1.34958001e-02,  3.92314494e-01,\n",
      "        -4.56926018e-01, -1.54782355e-01, -7.09666729e-01,\n",
      "        -2.48002782e-01, -3.20141017e-01, -8.06894898e-01,\n",
      "         4.40240316e-02],\n",
      "       [-2.21043274e-01, -3.24284248e-02,  1.65321663e-01,\n",
      "         2.38319188e-01, -2.71614522e-01, -3.12213544e-02,\n",
      "        -1.60529047e-01, -2.31815148e-02,  2.51059741e-01,\n",
      "         9.26916599e-02],\n",
      "       [ 2.43984312e-01,  2.47142054e-02,  1.29798874e-01,\n",
      "        -6.06085062e-02, -2.10530296e-01,  2.71118302e-02,\n",
      "         1.23843573e-01, -1.40647322e-01, -3.20757955e-01,\n",
      "         1.85067579e-01],\n",
      "       [-5.53415775e-01,  3.70753586e-01,  1.36233401e-02,\n",
      "         3.41136903e-01,  1.02188237e-01,  3.79453450e-01,\n",
      "        -4.11527932e-01, -2.38910079e-01,  2.00799063e-01,\n",
      "        -2.96506822e-01],\n",
      "       [-1.93671614e-01, -1.03591368e-01, -1.44636273e-01,\n",
      "         1.32888973e-01,  2.34315112e-01,  2.78649598e-01,\n",
      "        -6.17392398e-02, -2.81613737e-01,  4.73658778e-02,\n",
      "         2.01882839e-01],\n",
      "       [ 3.55687328e-02, -1.95854545e-01, -1.95848554e-01,\n",
      "         2.46315330e-01, -2.12828860e-01,  1.61005527e-01,\n",
      "         1.71558246e-01, -1.69437438e-01, -1.51630431e-01,\n",
      "         1.88875750e-01],\n",
      "       [ 1.59512654e-01,  4.51948643e-01, -3.53533425e-03,\n",
      "        -1.35240406e-01, -1.46900252e-01,  7.69123435e-02,\n",
      "        -9.26293731e-02, -1.75014883e-01, -2.25093409e-01,\n",
      "         1.66316405e-01],\n",
      "       [-8.23709965e-02, -1.85776904e-01, -8.16804469e-02,\n",
      "        -5.58411926e-02, -2.27020353e-01,  3.94000322e-01,\n",
      "         1.32776663e-01,  2.11080283e-01,  2.91755587e-01,\n",
      "         2.71307491e-02],\n",
      "       [-1.26259401e-01,  5.72854221e-01,  1.36840492e-01,\n",
      "        -1.62224337e-01, -1.11793287e-01, -2.18840778e-01,\n",
      "         4.87280590e-03,  2.78158928e-03,  8.31621960e-02,\n",
      "        -1.19556755e-01],\n",
      "       [ 1.15391605e-01,  1.50017336e-01,  1.22541048e-01,\n",
      "        -1.74872447e-02, -3.24405218e-03,  2.27123216e-01,\n",
      "         5.01946807e-02, -1.33200869e-01,  2.28547201e-01,\n",
      "         8.42431560e-02],\n",
      "       [-3.40215296e-01,  2.21471444e-01,  1.55171067e-01,\n",
      "         1.48020476e-01, -1.03625208e-01,  1.64272621e-01,\n",
      "         2.81308591e-02, -2.50043839e-01,  2.11093560e-01,\n",
      "         1.58431709e-01],\n",
      "       [-5.78677431e-02,  5.31691611e-01,  2.59411156e-01,\n",
      "         4.65210304e-02,  1.84345379e-01, -4.19663936e-01,\n",
      "        -1.98395327e-01, -1.58808589e-01, -1.04892902e-01,\n",
      "        -1.77363157e-01],\n",
      "       [ 6.41030222e-02, -1.11726418e-01,  3.93851429e-01,\n",
      "        -4.66719359e-01,  2.03941256e-01,  1.81364521e-01,\n",
      "         7.33588263e-02, -8.99983346e-02,  5.10795228e-03,\n",
      "         1.85777202e-01],\n",
      "       [ 1.38478264e-01,  8.94326717e-02,  3.91133875e-02,\n",
      "         1.68766692e-01, -1.01707667e-01,  2.47078851e-01,\n",
      "        -1.26914367e-01, -1.32760137e-01,  2.03706071e-01,\n",
      "         4.98045422e-02],\n",
      "       [ 5.18655218e-02,  6.10199928e-01, -7.64309019e-02,\n",
      "        -2.65604258e-02,  4.89494540e-02,  3.22228342e-01,\n",
      "         6.37191311e-02, -5.04912101e-02,  5.47507107e-02,\n",
      "        -1.44733801e-01]], dtype=float32), array([-0.0412581 ,  0.00011525,  0.01929276,  0.01239772, -0.0078637 ,\n",
      "        0.07032938,  0.01763121,  0.00091413,  0.05935137,  0.02863736],\n",
      "      dtype=float32)]\n",
      "relu_1 : []\n",
      "dense_2 : [array([[-0.0222058 ,  0.8783352 ,  0.13753499],\n",
      "       [ 0.15763982,  0.59507847,  0.42409623],\n",
      "       [-0.30941057, -0.24753378,  0.52852297],\n",
      "       [ 0.2726965 ,  0.2358899 , -0.40021098],\n",
      "       [ 0.40309617,  0.418579  ,  0.06302515],\n",
      "       [ 0.28233212, -0.03047479, -0.26235744],\n",
      "       [ 0.7082887 ,  0.41591513, -0.34484595],\n",
      "       [-0.17701054,  0.6747161 , -0.14955333],\n",
      "       [-0.02934626, -0.54838395, -0.4373713 ],\n",
      "       [ 0.32119584, -0.6034275 ,  0.55544865]], dtype=float32), array([ 0.02990199, -0.01626817,  0.00017452], dtype=float32)]\n",
      "output_softmax : []\n"
     ]
    }
   ],
   "source": [
    "for layer in toy_lstm.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name, \":\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d259fd",
   "metadata": {},
   "source": [
    "### After checking the weight of our toy model before quantization, we can finally do our Post-training quantization!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d429c",
   "metadata": {},
   "source": [
    "### For doing Post-training quantization, we need to create a \"config\" to quantize each layer separately(we don't need to quantize the input layer and the last layer when doing quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e730ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # give quantize-paramter to LSTM layer\n",
    "    \"QLSTM\":{\n",
    "        \"kernel_quantizer\" : f\"quantized_bits(6,2,1)\",\n",
    "            \"bias_quantizer\" : f\"quantized_bits(6,2,1)\",\n",
    "            \"recurrent_quantizer\": f\"quantized_bits(6,2,1)\",\n",
    "            \"state_quantizer\" : f\"quantized_bits(6,2,1)\"\n",
    "    },\n",
    "    # give quantize-paramter to all three Dense layer\n",
    "    \"QDense\":{\n",
    "        \"kernel_quantizer\" : f\"quantized_bits(6,2,1)\",\n",
    "        \"bias_quantizer\" : f\"quantized_bits(6,2,1)\"\n",
    "    },\n",
    "    # give quantizate-paramter to the first Activation layer\n",
    "    \"relu_0\" : f\"quantized_relu(6,2,1)\",\n",
    "    # give quantizate-paramter to the second Activation layer\n",
    "    \"relu_1\" : f\"quantized_relu(6,2,1)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615949a2",
   "metadata": {},
   "source": [
    "### Then we use the \"model_quantize\" function to quantize our toy lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8638864",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_qlstm = model_quantize(toy_lstm, config, 6, transfer_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c9ef5",
   "metadata": {},
   "source": [
    "### We can also check the quantize-parameter we provided to our toy model by printing them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b00bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "lstm1 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1) recurrent: quantized_bits(6,2,1,alpha='auto_po2') state: quantized_bits(6,2,1)\n",
      "dense_0 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "relu_0\n",
      "dense_1 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "relu_1\n",
      "dense_2 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "output_softmax\n"
     ]
    }
   ],
   "source": [
    "for layer in toy_qlstm.layers:\n",
    "            if hasattr(layer, \"recurrent_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal), \n",
    "                     \"recurrent:\", str(layer.recurrent_quantizer_internal), \"state:\", str(layer.state_quantizer_internal))\n",
    "            elif hasattr(layer, \"kernel_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "            elif hasattr(layer, \"quantized_relu\"):\n",
    "                print(layer.name, \"quantized_relu:\", str(layer.quantizer))\n",
    "            else:\n",
    "                print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dd8d7",
   "metadata": {},
   "source": [
    "### To check if we quantized our model successfully, we need to check the weight for our model after quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08a589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lstm1': {'weights': [array([[-0.484375, -0.484375,  0.5     , ...,  0.96875 ,  0.015625,\n",
       "            0.15625 ],\n",
       "          [-0.15625 ,  0.484375, -0.375   , ..., -0.09375 ,  0.40625 ,\n",
       "           -0.09375 ],\n",
       "          [ 0.1875  , -0.03125 , -0.78125 , ...,  0.46875 , -0.09375 ,\n",
       "            0.3125  ],\n",
       "          [-0.140625,  0.484375, -0.625   , ...,  0.25    ,  0.09375 ,\n",
       "           -0.375   ],\n",
       "          [ 0.34375 , -0.09375 ,  0.      , ..., -0.53125 ,  0.015625,\n",
       "            0.96875 ],\n",
       "          [-0.34375 , -0.484375, -0.34375 , ...,  0.125   , -0.03125 ,\n",
       "            0.375   ]], dtype=float32),\n",
       "   array([[ 0.171875,  0.15625 ,  0.078125, ..., -0.125   , -0.078125,\n",
       "           -0.203125],\n",
       "          [ 0.      ,  0.140625,  0.      , ..., -0.203125, -0.21875 ,\n",
       "           -0.109375],\n",
       "          [ 0.046875,  0.078125,  0.03125 , ...,  0.015625, -0.078125,\n",
       "            0.03125 ],\n",
       "          ...,\n",
       "          [-0.171875, -0.015625,  0.078125, ...,  0.03125 ,  0.0625  ,\n",
       "            0.      ],\n",
       "          [-0.015625, -0.25    , -0.03125 , ..., -0.09375 ,  0.21875 ,\n",
       "            0.125   ],\n",
       "          [ 0.      ,  0.078125, -0.046875, ..., -0.046875, -0.28125 ,\n",
       "           -0.3125  ]], dtype=float32),\n",
       "   array([ 0.   ,  0.375,  0.125,  0.25 ,  0.   ,  0.125,  0.   ,  0.25 ,\n",
       "           0.125,  0.   ,  0.   ,  0.125,  0.125,  0.25 ,  0.125,  0.   ,\n",
       "           0.125,  0.   ,  0.125,  0.   ,  0.125,  0.125,  0.   ,  0.125,\n",
       "           0.   ,  0.125,  0.   ,  0.   ,  0.125,  0.25 ,  0.25 , -0.125,\n",
       "           0.125,  0.   ,  0.125,  0.125,  0.   ,  0.125,  0.125,  0.25 ,\n",
       "           0.125,  0.125,  0.125,  0.   ,  0.125,  0.125,  0.   ,  0.125,\n",
       "           0.25 ,  0.   ,  0.   ,  0.125,  0.125,  0.   ,  0.   ,  0.125,\n",
       "           0.   ,  0.   ,  0.125,  0.   ,  0.125,  0.   ,  0.125,  0.125,\n",
       "           0.   ,  0.   , -0.125,  0.25 ,  0.   ,  0.125,  0.125,  0.   ,\n",
       "           0.125, -0.25 ,  0.   ,  0.   ,  0.   ,  0.   ,  0.125,  0.125,\n",
       "           0.   ,  0.125,  0.125,  0.125, -0.125,  0.125,  0.   ,  0.   ,\n",
       "           0.   ,  0.125,  0.25 ,  0.   ,  0.25 ,  0.   ,  0.125,  0.125,\n",
       "           0.   ,  0.25 ,  0.   ,  0.125,  0.125,  0.   ,  0.125,  0.5  ,\n",
       "           0.   ,  0.   ,  0.   ,  0.125,  0.   ,  0.125,  0.   ,  0.25 ,\n",
       "           0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.125,  0.   ,  0.125,\n",
       "           1.   ,  1.   ,  1.   ,  1.   ,  1.125,  1.   ,  1.   ,  1.   ,\n",
       "           1.   ,  0.875,  1.   ,  1.125,  1.125,  1.125,  1.125,  1.125,\n",
       "           1.125,  1.125,  1.125,  1.125,  1.   ,  1.125,  1.125,  1.125,\n",
       "           1.125,  1.   ,  1.125,  1.   ,  1.125,  1.25 ,  1.125,  1.125,\n",
       "           1.125,  1.   ,  1.   ,  1.   ,  1.125,  1.   ,  1.   ,  1.125,\n",
       "           1.   ,  0.875,  1.   ,  1.   ,  1.125,  0.875,  1.   ,  1.125,\n",
       "           1.125,  1.125,  1.   ,  1.125,  0.875,  1.   ,  1.   ,  1.   ,\n",
       "           1.   ,  1.   ,  1.   ,  1.125,  1.   ,  1.   ,  1.   ,  1.   ,\n",
       "           1.   ,  1.   ,  1.   ,  1.   ,  1.125,  1.125,  1.125,  1.   ,\n",
       "           1.   ,  1.   ,  1.125,  1.   ,  1.   ,  1.   ,  1.   ,  1.125,\n",
       "           1.   ,  1.   ,  1.125,  1.   ,  1.125,  0.875,  1.   ,  1.125,\n",
       "           1.   ,  1.125,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ,\n",
       "           1.125,  1.125,  1.   ,  1.   ,  1.   ,  1.125,  1.   ,  1.   ,\n",
       "           1.   ,  1.125,  1.125,  1.   ,  1.125,  1.   ,  1.125,  1.   ,\n",
       "           1.   ,  1.   ,  1.   ,  1.   ,  1.125,  1.   ,  1.125,  1.125,\n",
       "           0.   , -0.25 , -0.125,  0.125,  0.   ,  0.125,  0.   , -0.125,\n",
       "           0.   ,  0.   ,  0.125,  0.125,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "           0.   , -0.125,  0.   ,  0.125,  0.   ,  0.   ,  0.   , -0.125,\n",
       "           0.   ,  0.25 ,  0.125,  0.   ,  0.125,  0.25 ,  0.   ,  0.125,\n",
       "           0.   ,  0.   ,  0.125,  0.125,  0.   ,  0.   ,  0.   ,  0.125,\n",
       "           0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   , -0.125,\n",
       "           0.   ,  0.   , -0.125, -0.125,  0.   ,  0.   , -0.125,  0.   ,\n",
       "           0.   ,  0.125,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,\n",
       "           0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.125,  0.   , -0.125,\n",
       "           0.   ,  0.   ,  0.125, -0.125,  0.   , -0.125,  0.   ,  0.   ,\n",
       "           0.   ,  0.   ,  0.   , -0.125, -0.125,  0.   ,  0.   ,  0.125,\n",
       "           0.   , -0.125,  0.   , -0.125,  0.   ,  0.   , -0.125,  0.   ,\n",
       "           0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.125,\n",
       "           0.125,  0.   , -0.125, -0.25 ,  0.   ,  0.   ,  0.   ,  0.125,\n",
       "           0.   ,  0.   ,  0.   ,  0.   ,  0.125,  0.   ,  0.   , -0.375,\n",
       "           0.125,  0.125,  0.125,  0.5  ,  0.125,  0.125,  0.125,  0.5  ,\n",
       "           0.   ,  0.125,  0.125,  0.25 ,  0.25 ,  0.125,  0.125,  0.25 ,\n",
       "           0.125,  0.125,  0.125,  0.125,  0.125,  0.125,  0.125,  0.25 ,\n",
       "           0.125,  0.25 ,  0.125,  0.125,  0.   ,  0.25 ,  0.125,  0.125,\n",
       "           0.125,  0.125,  0.125,  0.   ,  0.125,  0.25 ,  0.   ,  0.   ,\n",
       "           0.125,  0.125,  0.25 ,  0.25 ,  0.   ,  0.125,  0.125,  0.25 ,\n",
       "           0.25 ,  0.125,  0.   ,  0.125,  0.125,  0.125,  0.125,  0.125,\n",
       "           0.125,  0.125,  0.125,  0.   ,  0.125,  0.   ,  0.125,  0.25 ,\n",
       "           0.125,  0.   ,  0.125,  0.375,  0.125,  0.125,  0.125,  0.25 ,\n",
       "           0.125,  0.125,  0.125,  0.   ,  0.125,  0.   ,  0.   ,  0.125,\n",
       "           0.125,  0.125,  0.125,  0.125,  0.25 ,  0.125,  0.125,  0.125,\n",
       "           0.   ,  0.125,  0.125,  0.25 ,  0.25 ,  0.125,  0.125,  0.125,\n",
       "           0.   ,  0.25 ,  0.125,  0.   ,  0.125,  0.   ,  0.125,  0.125,\n",
       "           0.125,  0.125,  0.125,  0.25 ,  0.125,  0.125,  0.   ,  0.125,\n",
       "           0.25 ,  0.   ,  0.125,  0.   ,  0.125,  0.125,  0.125,  0.25 ],\n",
       "         dtype=float32)]},\n",
       " 'dense_0': {'weights': [array([[ 0.2265625,  0.15625  ,  0.359375 , ...,  0.09375  , -0.2109375,\n",
       "           -0.1015625],\n",
       "          [ 0.046875 , -0.078125 , -0.109375 , ...,  0.125    ,  0.078125 ,\n",
       "           -0.0234375],\n",
       "          [ 0.0234375, -0.0703125, -0.015625 , ..., -0.140625 , -0.109375 ,\n",
       "           -0.1015625],\n",
       "          ...,\n",
       "          [ 0.15625  , -0.0859375, -0.171875 , ...,  0.078125 , -0.125    ,\n",
       "            0.2265625],\n",
       "          [-0.0703125, -0.09375  ,  0.09375  , ...,  0.140625 , -0.03125  ,\n",
       "           -0.1953125],\n",
       "          [ 0.078125 , -0.015625 , -0.109375 , ..., -0.078125 , -0.0390625,\n",
       "            0.015625 ]], dtype=float32),\n",
       "   array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "          0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "          0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "          0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "          0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125,\n",
       "          0.   , 0.   , 0.   , 0.   , 0.   ], dtype=float32)]},\n",
       " 'dense_1': {'weights': [array([[-0.15625  , -0.0625   , -0.078125 , -0.359375 , -0.1328125,\n",
       "           -0.375    , -0.375    ,  0.0625   ,  0.       ,  0.125    ],\n",
       "          [ 0.046875 ,  0.34375  ,  0.109375 ,  0.078125 , -0.2421875,\n",
       "           -0.21875  ,  0.15625  , -0.421875 , -0.21875  , -0.046875 ],\n",
       "          [ 0.21875  , -0.375    , -0.125    ,  0.28125  , -0.125    ,\n",
       "            0.28125  ,  0.15625  ,  0.09375  ,  0.       ,  0.125    ],\n",
       "          [-0.125    ,  0.       ,  0.078125 ,  0.078125 , -0.1875   ,\n",
       "           -0.0625   ,  0.3125   ,  0.03125  ,  0.125    ,  0.234375 ],\n",
       "          [-0.0625   ,  0.125    ,  0.171875 , -0.03125  , -0.1875   ,\n",
       "           -0.125    , -0.109375 ,  0.078125 , -0.0625   ,  0.125    ],\n",
       "          [ 0.15625  ,  0.09375  ,  0.046875 ,  0.09375  ,  0.1015625,\n",
       "            0.28125  ,  0.140625 , -0.296875 , -0.15625  ,  0.21875  ],\n",
       "          [ 0.       , -0.71875  , -0.203125 ,  0.21875  ,  0.1875   ,\n",
       "            0.6875   , -0.140625 ,  0.       ,  0.96875  ,  0.46875  ],\n",
       "          [ 0.375    ,  0.28125  , -0.234375 , -0.15625  , -0.046875 ,\n",
       "           -0.21875  , -0.09375  ,  0.125    , -0.28125  , -0.4375   ],\n",
       "          [-0.3125   , -0.1875   , -0.34375  ,  0.3125   ,  0.1484375,\n",
       "            0.25     ,  0.296875 , -0.296875 ,  0.03125  , -0.09375  ],\n",
       "          [-0.0625   ,  0.15625  , -0.296875 ,  0.265625 ,  0.15625  ,\n",
       "           -0.0625   , -0.015625 , -0.0625   , -0.25     , -0.171875 ],\n",
       "          [ 0.484375 ,  0.6875   , -0.078125 ,  0.046875 ,  0.1953125,\n",
       "           -0.3125   ,  0.015625 ,  0.03125  , -0.15625  , -0.4375   ],\n",
       "          [-0.375    , -0.15625  ,  0.140625 ,  0.09375  , -0.203125 ,\n",
       "            0.03125  , -0.28125  , -0.0625   , -0.15625  ,  0.21875  ],\n",
       "          [-0.0625   , -0.34375  ,  0.4375   , -0.359375 ,  0.1171875,\n",
       "            0.03125  ,  0.046875 , -0.125    , -0.03125  ,  0.234375 ],\n",
       "          [-0.21875  ,  0.21875  ,  0.203125 ,  0.125    , -0.09375  ,\n",
       "           -0.15625  , -0.140625 , -0.03125  , -0.0625   ,  0.       ],\n",
       "          [ 0.140625 ,  0.4375   ,  0.375    , -0.21875  ,  0.15625  ,\n",
       "           -0.25     , -0.03125  , -0.15625  , -0.0625   , -0.09375  ],\n",
       "          [-0.21875  , -0.125    , -0.0625   ,  0.265625 ,  0.       ,\n",
       "            0.0625   , -0.1875   ,  0.078125 ,  0.21875  , -0.015625 ],\n",
       "          [ 0.15625  ,  0.       , -0.09375  ,  0.15625  , -0.1875   ,\n",
       "            0.21875  , -0.03125  , -0.09375  , -0.09375  , -0.046875 ],\n",
       "          [ 0.15625  ,  0.625    , -0.25     ,  0.0625   ,  0.125    ,\n",
       "           -0.3125   ,  0.359375 ,  0.21875  , -0.53125  , -0.265625 ],\n",
       "          [ 0.265625 ,  0.1875   ,  0.046875 ,  0.03125  ,  0.015625 ,\n",
       "           -0.0625   , -0.34375  ,  0.171875 , -0.09375  ,  0.1875   ],\n",
       "          [-0.125    ,  0.       ,  0.015625 ,  0.203125 , -0.140625 ,\n",
       "           -0.09375  , -0.109375 ,  0.328125 ,  0.28125  , -0.078125 ],\n",
       "          [ 0.359375 ,  0.03125  ,  0.359375 , -0.28125  ,  0.0859375,\n",
       "           -0.125    , -0.359375 , -0.296875 , -0.5      ,  0.109375 ],\n",
       "          [-0.390625 ,  0.       ,  0.3125   , -0.171875 ,  0.09375  ,\n",
       "           -0.1875   , -0.203125 , -0.03125  , -0.09375  ,  0.390625 ],\n",
       "          [ 0.078125 ,  0.09375  , -0.28125  , -0.0625   ,  0.2109375,\n",
       "            0.3125   ,  0.015625 , -0.296875 ,  0.03125  , -0.296875 ],\n",
       "          [ 0.03125  ,  0.125    ,  0.015625 ,  0.015625 , -0.0625   ,\n",
       "           -0.09375  ,  0.015625 ,  0.078125 ,  0.21875  ,  0.1875   ],\n",
       "          [ 0.28125  , -0.40625  , -0.3125   ,  0.3125   , -0.234375 ,\n",
       "            0.34375  , -0.078125 ,  0.0625   ,  0.46875  ,  0.09375  ],\n",
       "          [-0.125    , -0.09375  ,  0.140625 ,  0.203125 , -0.1796875,\n",
       "           -0.0625   ,  0.1875   ,  0.296875 ,  0.21875  , -0.234375 ],\n",
       "          [-0.078125 ,  0.65625  ,  0.234375 ,  0.078125 , -0.15625  ,\n",
       "           -0.21875  ,  0.15625  ,  0.       , -0.1875   , -0.21875  ],\n",
       "          [ 0.140625 ,  0.375    ,  0.046875 ,  0.140625 ,  0.15625  ,\n",
       "           -0.0625   , -0.078125 , -0.21875  ,  0.28125  , -0.140625 ],\n",
       "          [-0.078125 ,  0.09375  ,  0.21875  , -0.28125  , -0.1015625,\n",
       "           -0.03125  , -0.28125  ,  0.09375  , -0.21875  , -0.109375 ],\n",
       "          [-0.234375 ,  0.4375   ,  0.25     ,  0.21875  , -0.1640625,\n",
       "            0.09375  , -0.078125 , -0.078125 , -0.25     , -0.0625   ],\n",
       "          [-0.03125  ,  0.6875   ,  0.265625 , -0.03125  ,  0.0859375,\n",
       "            0.09375  ,  0.25     , -0.015625 , -0.21875  , -0.171875 ],\n",
       "          [-0.203125 ,  0.21875  ,  0.1875   ,  0.1875   , -0.1875   ,\n",
       "           -0.09375  ,  0.046875 ,  0.21875  , -0.28125  ,  0.125    ],\n",
       "          [-0.140625 ,  0.21875  ,  0.125    , -0.171875 , -0.09375  ,\n",
       "           -0.125    ,  0.125    ,  0.09375  , -0.21875  , -0.03125  ],\n",
       "          [-0.109375 , -0.34375  ,  0.171875 , -0.03125  ,  0.0234375,\n",
       "           -0.1875   ,  0.078125 ,  0.046875 , -0.125    ,  0.328125 ],\n",
       "          [ 0.1875   , -0.46875  , -0.0625   , -0.09375  ,  0.       ,\n",
       "           -0.25     , -0.140625 ,  0.234375 ,  0.       ,  0.25     ],\n",
       "          [-0.1875   ,  0.       ,  0.390625 , -0.453125 , -0.15625  ,\n",
       "           -0.71875  , -0.25     , -0.3125   , -0.8125   ,  0.046875 ],\n",
       "          [-0.21875  , -0.03125  ,  0.171875 ,  0.234375 , -0.2421875,\n",
       "           -0.03125  , -0.15625  , -0.015625 ,  0.25     ,  0.09375  ],\n",
       "          [ 0.25     ,  0.03125  ,  0.125    , -0.0625   , -0.2109375,\n",
       "            0.03125  ,  0.125    , -0.140625 , -0.3125   ,  0.1875   ],\n",
       "          [-0.484375 ,  0.375    ,  0.015625 ,  0.34375  ,  0.1015625,\n",
       "            0.375    , -0.40625  , -0.234375 ,  0.1875   , -0.296875 ],\n",
       "          [-0.1875   , -0.09375  , -0.140625 ,  0.140625 ,  0.234375 ,\n",
       "            0.28125  , -0.0625   , -0.28125  ,  0.0625   ,  0.203125 ],\n",
       "          [ 0.03125  , -0.1875   , -0.203125 ,  0.25     , -0.2109375,\n",
       "            0.15625  ,  0.171875 , -0.171875 , -0.15625  ,  0.1875   ],\n",
       "          [ 0.15625  ,  0.4375   ,  0.       , -0.140625 , -0.1484375,\n",
       "            0.0625   , -0.09375  , -0.171875 , -0.21875  ,  0.171875 ],\n",
       "          [-0.078125 , -0.1875   , -0.078125 , -0.0625   , -0.2265625,\n",
       "            0.40625  ,  0.125    ,  0.21875  ,  0.28125  ,  0.03125  ],\n",
       "          [-0.125    ,  0.5625   ,  0.140625 , -0.15625  , -0.109375 ,\n",
       "           -0.21875  ,  0.       ,  0.       ,  0.09375  , -0.125    ],\n",
       "          [ 0.109375 ,  0.15625  ,  0.125    , -0.015625 ,  0.       ,\n",
       "            0.21875  ,  0.046875 , -0.140625 ,  0.21875  ,  0.078125 ],\n",
       "          [-0.34375  ,  0.21875  ,  0.15625  ,  0.140625 , -0.1015625,\n",
       "            0.15625  ,  0.03125  , -0.25     ,  0.21875  ,  0.15625  ],\n",
       "          [-0.0625   ,  0.53125  ,  0.265625 ,  0.046875 ,  0.1875   ,\n",
       "           -0.40625  , -0.203125 , -0.15625  , -0.09375  , -0.171875 ],\n",
       "          [ 0.0625   , -0.125    ,  0.390625 , -0.46875  ,  0.203125 ,\n",
       "            0.1875   ,  0.078125 , -0.09375  ,  0.       ,  0.1875   ],\n",
       "          [ 0.140625 ,  0.09375  ,  0.046875 ,  0.171875 , -0.1015625,\n",
       "            0.25     , -0.125    , -0.125    ,  0.21875  ,  0.046875 ],\n",
       "          [ 0.046875 ,  0.625    , -0.078125 , -0.03125  ,  0.046875 ,\n",
       "            0.3125   ,  0.0625   , -0.046875 ,  0.0625   , -0.140625 ]],\n",
       "         dtype=float32),\n",
       "   array([0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.   ,\n",
       "          0.   ], dtype=float32)]},\n",
       " 'dense_2': {'weights': [array([[-0.03125 ,  0.875   ,  0.140625],\n",
       "          [ 0.15625 ,  0.59375 ,  0.421875],\n",
       "          [-0.3125  , -0.25    ,  0.484375],\n",
       "          [ 0.28125 ,  0.25    , -0.40625 ],\n",
       "          [ 0.40625 ,  0.40625 ,  0.0625  ],\n",
       "          [ 0.28125 , -0.03125 , -0.265625],\n",
       "          [ 0.71875 ,  0.40625 , -0.34375 ],\n",
       "          [-0.1875  ,  0.6875  , -0.15625 ],\n",
       "          [-0.03125 , -0.5625  , -0.4375  ],\n",
       "          [ 0.3125  , -0.59375 ,  0.484375]], dtype=float32),\n",
       "   array([0., 0., 0.], dtype=float32)]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_quantized_weights(toy_qlstm, \"ptq2int5fra_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff2bd4",
   "metadata": {},
   "source": [
    "### By comparing the weight we get after training with the weight we get before training, we can tell that our model has been successfully quantized! Great job!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e9472",
   "metadata": {},
   "source": [
    "### For the last step in our Post-training quantization, we need to check and compare the accuracy of our model before quantization and after quantization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa59cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28fdd956",
   "metadata": {},
   "source": [
    "### 2.3: Now is your time to do Post-training quantization to a similiar model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a54e4",
   "metadata": {},
   "source": [
    "### You can download a toy model from this github page: https://github.com/uw-acme/HLS4ML_RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7238e",
   "metadata": {},
   "source": [
    "### The model we are using is another b-tag model with one GRU layer.\n",
    "### Here you can see how the model looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533098c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 15, 6)]           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 120)               46080     \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 50)                6050      \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " relu_1 (Activation)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 3)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,673\n",
      "Trainable params: 52,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def grumodel(max_len, n_var, rec_units, ndense=[50, 10], l1_reg=0,\n",
    "              l2_reg=0, rec_act='sigmoid', extra_lab='none', rec_kernel_init='VarianceScaling',\n",
    "             dense_kernel_init='lecun_uniform'):\n",
    "    \n",
    "    hidden = x_in = Input(shape=(max_len, n_var,))\n",
    "    hidden = GRU(units=rec_units,\n",
    "                  recurrent_activation = rec_act,\n",
    "                  kernel_initializer = rec_kernel_init, \n",
    "                  name = 'gru')(hidden)\n",
    "    \n",
    "    hidden = Dense(50, kernel_initializer=dense_kernel_init, name='dense_0' )(hidden)\n",
    "    hidden = Activation('relu', name = 'relu_0')(hidden)\n",
    "    \n",
    "    hidden = Dense(10, kernel_initializer=dense_kernel_init, name='dense_1' )(hidden)\n",
    "    hidden = Activation('relu', name = 'relu_1')(hidden)\n",
    "\n",
    "    hidden = Dense(3, kernel_initializer=dense_kernel_init, name = 'dense_2')(hidden)\n",
    "    hidden = Activation('softmax', name = 'output_softmax')(hidden)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=hidden)\n",
    "    \n",
    "    return model\n",
    "\n",
    "l1_reg = 0\n",
    "l2_reg = 0\n",
    "model = grumodel(15, 6, 120, [50, 10], l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7059a9",
   "metadata": {},
   "source": [
    "### Don't forget to check your model's weight before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aa4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the weight for our keras model\n",
    "# Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8659a",
   "metadata": {},
   "source": [
    "### Write the \"config\" for applying quantization to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Replace this line with your own code\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b14105",
   "metadata": {},
   "source": [
    "### Use the \"model_quantize\" function to quantize our toy lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d8d0f",
   "metadata": {},
   "source": [
    "### Check the quantize-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6859a51",
   "metadata": {},
   "source": [
    "### Check the weight for our quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this line with your own code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
