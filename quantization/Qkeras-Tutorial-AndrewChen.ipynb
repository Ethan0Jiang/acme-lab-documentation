{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccddbac",
   "metadata": {},
   "source": [
    "# Qkeras Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d3b6e",
   "metadata": {},
   "source": [
    "## Section 1: Preparation before quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b5101",
   "metadata": {},
   "source": [
    "### 1.1: Please run the following cell to check if your qkeras and other needed packages are installed and import correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c6a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qkeras\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, LSTM, Masking, Input, GRU, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d68ef",
   "metadata": {},
   "source": [
    "### 1.2 Download the training data from [this google drive](https://drive.google.com/drive/folders/1GhzO8Z9LvxzouAh5Ktq439S8YisJcM0X?usp=sharing) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a71046",
   "metadata": {},
   "source": [
    "### 1.3 The following three sections in our tutorial is corresponding to three different ways for doing quantization in Qkeras: **Post Training Quantization**, **Quantization Aware Training**, and **Auto Qkeras**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e54cd",
   "metadata": {},
   "source": [
    "## Section 2:  Post-training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217f2aa",
   "metadata": {},
   "source": [
    "### 2.1: What is Post-training Quantization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99286155",
   "metadata": {},
   "source": [
    "Post-training Quantization is a kind of efficient model compression technique, which can directly quantize neural network models after training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e6d52",
   "metadata": {},
   "source": [
    "### 2.2: How to do Post-training quantization with qkeras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673829f",
   "metadata": {},
   "source": [
    "First, we need to have a already-trainined keras model. You can train it by yourself (in option 1 part) or load the toy model dircetly (in option 2 part)\n",
    "<br>\n",
    "The toy model we are using is an toptag model with one LSTM layer. \n",
    "<br>\n",
    "Before starting your quantization you need to know what your model looks like. \n",
    "<br>\n",
    "model.summary() is a great method in keras that you will use frequently to check the layers in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af6f6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (LSTM)               (None, 5)                 240       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 5)                 30        \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 5)                 0         \n",
      "                                                                 \n",
      " layer5 (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "toy_lstm = Sequential()\n",
    "toy_lstm.add(LSTM(5, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "               name = 'layer1', input_shape = (20,6)))\n",
    "toy_lstm.add(Dense(5, kernel_initializer='glorot_normal', name='layer3'))\n",
    "toy_lstm.add(Activation('relu', name = 'relu_0'))\n",
    "toy_lstm.add(Dense(1, name = 'layer5'))\n",
    "toy_lstm.add(Activation('sigmoid', name = 'output_sigmoid'))\n",
    "\n",
    "toy_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb620c",
   "metadata": {},
   "source": [
    "(Option 1)Training the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a036bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "x_train = np.load('./x_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "y_train = y_train[:,4:5]\n",
    "\n",
    "# load testing data\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed96ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyihu\\anaconda3\\envs\\hls4ml-tutorial\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.6978 - accuracy: 0.4715\n",
      "Epoch 1: val_loss improved from inf to 0.69633, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 2s 47ms/step - loss: 0.6976 - accuracy: 0.4748 - val_loss: 0.6963 - val_accuracy: 0.4882\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.4922\n",
      "Epoch 2: val_loss improved from 0.69633 to 0.69463, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6957 - accuracy: 0.4922 - val_loss: 0.6946 - val_accuracy: 0.5218\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5555\n",
      "Epoch 3: val_loss improved from 0.69463 to 0.69261, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5555 - val_loss: 0.6926 - val_accuracy: 0.5891\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.6440\n",
      "Epoch 4: val_loss improved from 0.69261 to 0.68949, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.6440 - val_loss: 0.6895 - val_accuracy: 0.6496\n",
      "Epoch 5/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6872 - accuracy: 0.6918\n",
      "Epoch 5: val_loss improved from 0.68949 to 0.68261, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6869 - accuracy: 0.6922 - val_loss: 0.6826 - val_accuracy: 0.6938\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.7061\n",
      "Epoch 6: val_loss improved from 0.68261 to 0.66069, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6749 - accuracy: 0.7061 - val_loss: 0.6607 - val_accuracy: 0.7332\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.7448\n",
      "Epoch 7: val_loss improved from 0.66069 to 0.58678, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6329 - accuracy: 0.7448 - val_loss: 0.5868 - val_accuracy: 0.7871\n",
      "Epoch 8/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.5543 - accuracy: 0.7870\n",
      "Epoch 8: val_loss improved from 0.58678 to 0.50037, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5428 - accuracy: 0.7894 - val_loss: 0.5004 - val_accuracy: 0.8040\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.8065\n",
      "Epoch 9: val_loss improved from 0.50037 to 0.46350, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4824 - accuracy: 0.8065 - val_loss: 0.4635 - val_accuracy: 0.8134\n",
      "Epoch 10/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4562 - accuracy: 0.8150\n",
      "Epoch 10: val_loss improved from 0.46350 to 0.44111, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4533 - accuracy: 0.8159 - val_loss: 0.4411 - val_accuracy: 0.8201\n",
      "Epoch 11/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4368 - accuracy: 0.8217\n",
      "Epoch 11: val_loss improved from 0.44111 to 0.42746, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4354 - accuracy: 0.8221 - val_loss: 0.4275 - val_accuracy: 0.8251\n",
      "Epoch 12/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4257 - accuracy: 0.8250\n",
      "Epoch 12: val_loss improved from 0.42746 to 0.41845, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4248 - accuracy: 0.8254 - val_loss: 0.4184 - val_accuracy: 0.8281\n",
      "Epoch 13/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.4186 - accuracy: 0.8270\n",
      "Epoch 13: val_loss improved from 0.41845 to 0.41248, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4179 - accuracy: 0.8274 - val_loss: 0.4125 - val_accuracy: 0.8301\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.8290\n",
      "Epoch 14: val_loss improved from 0.41248 to 0.40907, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4125 - accuracy: 0.8290 - val_loss: 0.4091 - val_accuracy: 0.8316\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8303\n",
      "Epoch 15: val_loss improved from 0.40907 to 0.40475, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4086 - accuracy: 0.8303 - val_loss: 0.4047 - val_accuracy: 0.8325\n",
      "Epoch 16/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4054 - accuracy: 0.8316\n",
      "Epoch 16: val_loss improved from 0.40475 to 0.40156, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.8312 - val_loss: 0.4016 - val_accuracy: 0.8339\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8323\n",
      "Epoch 17: val_loss improved from 0.40156 to 0.39932, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4030 - accuracy: 0.8323 - val_loss: 0.3993 - val_accuracy: 0.8345\n",
      "Epoch 18/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4013 - accuracy: 0.8330\n",
      "Epoch 18: val_loss improved from 0.39932 to 0.39738, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4010 - accuracy: 0.8332 - val_loss: 0.3974 - val_accuracy: 0.8350\n",
      "Epoch 19/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3990 - accuracy: 0.8336\n",
      "Epoch 19: val_loss improved from 0.39738 to 0.39615, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3996 - accuracy: 0.8334 - val_loss: 0.3961 - val_accuracy: 0.8353\n",
      "Epoch 20/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3974 - accuracy: 0.8346\n",
      "Epoch 20: val_loss improved from 0.39615 to 0.39403, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3976 - accuracy: 0.8344 - val_loss: 0.3940 - val_accuracy: 0.8362\n",
      "Epoch 21/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3967 - accuracy: 0.8348\n",
      "Epoch 21: val_loss improved from 0.39403 to 0.39267, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3958 - accuracy: 0.8351 - val_loss: 0.3927 - val_accuracy: 0.8364\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8357\n",
      "Epoch 22: val_loss improved from 0.39267 to 0.39123, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3946 - accuracy: 0.8357 - val_loss: 0.3912 - val_accuracy: 0.8372\n",
      "Epoch 23/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3942 - accuracy: 0.8355\n",
      "Epoch 23: val_loss improved from 0.39123 to 0.38961, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8361 - val_loss: 0.3896 - val_accuracy: 0.8380\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8365\n",
      "Epoch 24: val_loss improved from 0.38961 to 0.38844, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3922 - accuracy: 0.8365 - val_loss: 0.3884 - val_accuracy: 0.8385\n",
      "Epoch 25/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3905 - accuracy: 0.8368\n",
      "Epoch 25: val_loss did not improve from 0.38844\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8368 - val_loss: 0.3888 - val_accuracy: 0.8382\n",
      "Epoch 26/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3905 - accuracy: 0.8372\n",
      "Epoch 26: val_loss improved from 0.38844 to 0.38726, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3904 - accuracy: 0.8375 - val_loss: 0.3873 - val_accuracy: 0.8389\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.8382\n",
      "Epoch 27: val_loss improved from 0.38726 to 0.38488, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3886 - accuracy: 0.8382 - val_loss: 0.3849 - val_accuracy: 0.8402\n",
      "Epoch 28/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3859 - accuracy: 0.8395\n",
      "Epoch 28: val_loss improved from 0.38488 to 0.38462, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3877 - accuracy: 0.8387 - val_loss: 0.3846 - val_accuracy: 0.8411\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8387\n",
      "Epoch 29: val_loss improved from 0.38462 to 0.38309, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3872 - accuracy: 0.8387 - val_loss: 0.3831 - val_accuracy: 0.8407\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8397\n",
      "Epoch 30: val_loss improved from 0.38309 to 0.38177, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3858 - accuracy: 0.8397 - val_loss: 0.3818 - val_accuracy: 0.8413\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8401\n",
      "Epoch 31: val_loss did not improve from 0.38177\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3845 - accuracy: 0.8401 - val_loss: 0.3820 - val_accuracy: 0.8410\n",
      "Epoch 32/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3848 - accuracy: 0.8403\n",
      "Epoch 32: val_loss improved from 0.38177 to 0.37965, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3837 - accuracy: 0.8404 - val_loss: 0.3796 - val_accuracy: 0.8430\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8409\n",
      "Epoch 33: val_loss improved from 0.37965 to 0.37868, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.8409 - val_loss: 0.3787 - val_accuracy: 0.8430\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8415\n",
      "Epoch 34: val_loss improved from 0.37868 to 0.37853, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3819 - accuracy: 0.8415 - val_loss: 0.3785 - val_accuracy: 0.8428\n",
      "Epoch 35/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3805 - accuracy: 0.8423\n",
      "Epoch 35: val_loss improved from 0.37853 to 0.37680, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3808 - accuracy: 0.8418 - val_loss: 0.3768 - val_accuracy: 0.8447\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8423\n",
      "Epoch 36: val_loss improved from 0.37680 to 0.37590, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3799 - accuracy: 0.8423 - val_loss: 0.3759 - val_accuracy: 0.8447\n",
      "Epoch 37/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3785 - accuracy: 0.8429\n",
      "Epoch 37: val_loss improved from 0.37590 to 0.37520, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3791 - accuracy: 0.8425 - val_loss: 0.3752 - val_accuracy: 0.8451\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8428\n",
      "Epoch 38: val_loss improved from 0.37520 to 0.37504, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3787 - accuracy: 0.8428 - val_loss: 0.3750 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8435\n",
      "Epoch 39: val_loss improved from 0.37504 to 0.37334, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3777 - accuracy: 0.8435 - val_loss: 0.3733 - val_accuracy: 0.8465\n",
      "Epoch 40/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3772 - accuracy: 0.8433\n",
      "Epoch 40: val_loss improved from 0.37334 to 0.37272, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3773 - accuracy: 0.8436 - val_loss: 0.3727 - val_accuracy: 0.8469\n",
      "Epoch 41/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3764 - accuracy: 0.8439\n",
      "Epoch 41: val_loss improved from 0.37272 to 0.37215, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3764 - accuracy: 0.8438 - val_loss: 0.3721 - val_accuracy: 0.8474\n",
      "Epoch 42/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3760 - accuracy: 0.8444\n",
      "Epoch 42: val_loss improved from 0.37215 to 0.37138, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8440 - val_loss: 0.3714 - val_accuracy: 0.8478\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8445\n",
      "Epoch 43: val_loss did not improve from 0.37138\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3752 - accuracy: 0.8445 - val_loss: 0.3716 - val_accuracy: 0.8475\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8440\n",
      "Epoch 44: val_loss improved from 0.37138 to 0.37091, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3756 - accuracy: 0.8440 - val_loss: 0.3709 - val_accuracy: 0.8476\n",
      "Epoch 45/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3740 - accuracy: 0.8451\n",
      "Epoch 45: val_loss improved from 0.37091 to 0.36994, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3743 - accuracy: 0.8447 - val_loss: 0.3699 - val_accuracy: 0.8486\n",
      "Epoch 46/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3727 - accuracy: 0.8458\n",
      "Epoch 46: val_loss improved from 0.36994 to 0.36962, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3735 - accuracy: 0.8449 - val_loss: 0.3696 - val_accuracy: 0.8486\n",
      "Epoch 47/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3742 - accuracy: 0.8442\n",
      "Epoch 47: val_loss improved from 0.36962 to 0.36938, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3731 - accuracy: 0.8451 - val_loss: 0.3694 - val_accuracy: 0.8485\n",
      "Epoch 48/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3730 - accuracy: 0.8455\n",
      "Epoch 48: val_loss improved from 0.36938 to 0.36916, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3737 - accuracy: 0.8452 - val_loss: 0.3692 - val_accuracy: 0.8486\n",
      "Epoch 49/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3724 - accuracy: 0.8455\n",
      "Epoch 49: val_loss improved from 0.36916 to 0.36813, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.8454 - val_loss: 0.3681 - val_accuracy: 0.8490\n",
      "Epoch 50/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3727 - accuracy: 0.8455\n",
      "Epoch 50: val_loss did not improve from 0.36813\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3721 - accuracy: 0.8458 - val_loss: 0.3684 - val_accuracy: 0.8491\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.8458\n",
      "Epoch 51: val_loss improved from 0.36813 to 0.36771, saving model to lstm_training\\toptag_model_lstm.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3719 - accuracy: 0.8458 - val_loss: 0.3677 - val_accuracy: 0.8495\n",
      "Epoch 52/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3712 - accuracy: 0.8458\n",
      "Epoch 52: val_loss did not improve from 0.36771\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3716 - accuracy: 0.8458 - val_loss: 0.3690 - val_accuracy: 0.8477\n",
      "Epoch 53/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3713 - accuracy: 0.8461\n",
      "Epoch 53: val_loss improved from 0.36771 to 0.36682, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.8460 - val_loss: 0.3668 - val_accuracy: 0.8497\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.8462\n",
      "Epoch 54: val_loss did not improve from 0.36682\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3708 - accuracy: 0.8462 - val_loss: 0.3674 - val_accuracy: 0.8499\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.8463\n",
      "Epoch 55: val_loss improved from 0.36682 to 0.36648, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3705 - accuracy: 0.8463 - val_loss: 0.3665 - val_accuracy: 0.8494\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8460\n",
      "Epoch 56: val_loss did not improve from 0.36648\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3706 - accuracy: 0.8460 - val_loss: 0.3681 - val_accuracy: 0.8492\n",
      "Epoch 57/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3693 - accuracy: 0.8470\n",
      "Epoch 57: val_loss improved from 0.36648 to 0.36602, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3701 - accuracy: 0.8465 - val_loss: 0.3660 - val_accuracy: 0.8498\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8464\n",
      "Epoch 58: val_loss did not improve from 0.36602\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3700 - accuracy: 0.8464 - val_loss: 0.3660 - val_accuracy: 0.8503\n",
      "Epoch 59/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3706 - accuracy: 0.8465\n",
      "Epoch 59: val_loss did not improve from 0.36602\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3693 - accuracy: 0.8468 - val_loss: 0.3666 - val_accuracy: 0.8491\n",
      "Epoch 60/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3684 - accuracy: 0.8471\n",
      "Epoch 60: val_loss improved from 0.36602 to 0.36470, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3694 - accuracy: 0.8466 - val_loss: 0.3647 - val_accuracy: 0.8506\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8468\n",
      "Epoch 61: val_loss improved from 0.36470 to 0.36444, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3689 - accuracy: 0.8468 - val_loss: 0.3644 - val_accuracy: 0.8506\n",
      "Epoch 62/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3674 - accuracy: 0.8473\n",
      "Epoch 62: val_loss did not improve from 0.36444\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3685 - accuracy: 0.8470 - val_loss: 0.3658 - val_accuracy: 0.8492\n",
      "Epoch 63/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3681 - accuracy: 0.8468\n",
      "Epoch 63: val_loss did not improve from 0.36444\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3687 - accuracy: 0.8467 - val_loss: 0.3661 - val_accuracy: 0.8491\n",
      "Epoch 64/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3695 - accuracy: 0.8467\n",
      "Epoch 64: val_loss did not improve from 0.36444\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3685 - accuracy: 0.8471 - val_loss: 0.3645 - val_accuracy: 0.8507\n",
      "Epoch 65/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3682 - accuracy: 0.8472\n",
      "Epoch 65: val_loss improved from 0.36444 to 0.36373, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8473 - val_loss: 0.3637 - val_accuracy: 0.8509\n",
      "Epoch 66/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3687 - accuracy: 0.8469\n",
      "Epoch 66: val_loss did not improve from 0.36373\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3683 - accuracy: 0.8471 - val_loss: 0.3641 - val_accuracy: 0.8500\n",
      "Epoch 67/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3672 - accuracy: 0.8478\n",
      "Epoch 67: val_loss improved from 0.36373 to 0.36322, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3675 - accuracy: 0.8474 - val_loss: 0.3632 - val_accuracy: 0.8511\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8475\n",
      "Epoch 68: val_loss improved from 0.36322 to 0.36301, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.8475 - val_loss: 0.3630 - val_accuracy: 0.8510\n",
      "Epoch 69/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3668 - accuracy: 0.8479\n",
      "Epoch 69: val_loss improved from 0.36301 to 0.36259, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3668 - accuracy: 0.8478 - val_loss: 0.3626 - val_accuracy: 0.8511\n",
      "Epoch 70/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3668 - accuracy: 0.8478\n",
      "Epoch 70: val_loss did not improve from 0.36259\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3667 - accuracy: 0.8477 - val_loss: 0.3633 - val_accuracy: 0.8504\n",
      "Epoch 71/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3666 - accuracy: 0.8479\n",
      "Epoch 71: val_loss improved from 0.36259 to 0.36224, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3663 - accuracy: 0.8480 - val_loss: 0.3622 - val_accuracy: 0.8509\n",
      "Epoch 72/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3658 - accuracy: 0.8483\n",
      "Epoch 72: val_loss improved from 0.36224 to 0.36185, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3659 - accuracy: 0.8482 - val_loss: 0.3618 - val_accuracy: 0.8514\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8482\n",
      "Epoch 73: val_loss did not improve from 0.36185\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3658 - accuracy: 0.8482 - val_loss: 0.3632 - val_accuracy: 0.8512\n",
      "Epoch 74/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3661 - accuracy: 0.8473\n",
      "Epoch 74: val_loss did not improve from 0.36185\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3659 - accuracy: 0.8479 - val_loss: 0.3620 - val_accuracy: 0.8508\n",
      "Epoch 75/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3660 - accuracy: 0.8479\n",
      "Epoch 75: val_loss did not improve from 0.36185\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3652 - accuracy: 0.8483 - val_loss: 0.3623 - val_accuracy: 0.8512\n",
      "Epoch 76/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3650 - accuracy: 0.8484\n",
      "Epoch 76: val_loss improved from 0.36185 to 0.36125, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3652 - accuracy: 0.8483 - val_loss: 0.3612 - val_accuracy: 0.8512\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8484\n",
      "Epoch 77: val_loss improved from 0.36125 to 0.36101, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3651 - accuracy: 0.8484 - val_loss: 0.3610 - val_accuracy: 0.8514\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.8483\n",
      "Epoch 78: val_loss did not improve from 0.36101\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3649 - accuracy: 0.8483 - val_loss: 0.3617 - val_accuracy: 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3647 - accuracy: 0.8483\n",
      "Epoch 79: val_loss did not improve from 0.36101\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3646 - accuracy: 0.8485 - val_loss: 0.3611 - val_accuracy: 0.8517\n",
      "Epoch 80/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3641 - accuracy: 0.8487\n",
      "Epoch 80: val_loss improved from 0.36101 to 0.36055, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3643 - accuracy: 0.8487 - val_loss: 0.3605 - val_accuracy: 0.8516\n",
      "Epoch 81/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3643 - accuracy: 0.8487\n",
      "Epoch 81: val_loss improved from 0.36055 to 0.36006, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3640 - accuracy: 0.8489 - val_loss: 0.3601 - val_accuracy: 0.8519\n",
      "Epoch 82/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3635 - accuracy: 0.8491\n",
      "Epoch 82: val_loss improved from 0.36006 to 0.35995, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3638 - accuracy: 0.8489 - val_loss: 0.3599 - val_accuracy: 0.8517\n",
      "Epoch 83/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3636 - accuracy: 0.8490\n",
      "Epoch 83: val_loss improved from 0.35995 to 0.35970, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3640 - accuracy: 0.8487 - val_loss: 0.3597 - val_accuracy: 0.8519\n",
      "Epoch 84/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3656 - accuracy: 0.8472\n",
      "Epoch 84: val_loss did not improve from 0.35970\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3648 - accuracy: 0.8482 - val_loss: 0.3609 - val_accuracy: 0.8511\n",
      "Epoch 85/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3634 - accuracy: 0.8491\n",
      "Epoch 85: val_loss improved from 0.35970 to 0.35942, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3635 - accuracy: 0.8490 - val_loss: 0.3594 - val_accuracy: 0.8520\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8487\n",
      "Epoch 86: val_loss did not improve from 0.35942\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3634 - accuracy: 0.8487 - val_loss: 0.3595 - val_accuracy: 0.8520\n",
      "Epoch 87/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3630 - accuracy: 0.8490\n",
      "Epoch 87: val_loss did not improve from 0.35942\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3630 - accuracy: 0.8492 - val_loss: 0.3600 - val_accuracy: 0.8522\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8489\n",
      "Epoch 88: val_loss did not improve from 0.35942\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3633 - accuracy: 0.8489 - val_loss: 0.3594 - val_accuracy: 0.8519\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.8491\n",
      "Epoch 89: val_loss improved from 0.35942 to 0.35923, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3630 - accuracy: 0.8491 - val_loss: 0.3592 - val_accuracy: 0.8522\n",
      "Epoch 90/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3624 - accuracy: 0.8492\n",
      "Epoch 90: val_loss improved from 0.35923 to 0.35866, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3628 - accuracy: 0.8491 - val_loss: 0.3587 - val_accuracy: 0.8521\n",
      "Epoch 91/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3621 - accuracy: 0.8493\n",
      "Epoch 91: val_loss did not improve from 0.35866\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3623 - accuracy: 0.8494 - val_loss: 0.3590 - val_accuracy: 0.8522\n",
      "Epoch 92/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3623 - accuracy: 0.8491\n",
      "Epoch 92: val_loss did not improve from 0.35866\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3622 - accuracy: 0.8493 - val_loss: 0.3594 - val_accuracy: 0.8522\n",
      "Epoch 93/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3631 - accuracy: 0.8491\n",
      "Epoch 93: val_loss did not improve from 0.35866\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3629 - accuracy: 0.8492 - val_loss: 0.3595 - val_accuracy: 0.8522\n",
      "Epoch 94/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3632 - accuracy: 0.8484\n",
      "Epoch 94: val_loss did not improve from 0.35866\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3623 - accuracy: 0.8489 - val_loss: 0.3593 - val_accuracy: 0.8519\n",
      "Epoch 95/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3612 - accuracy: 0.8494\n",
      "Epoch 95: val_loss improved from 0.35866 to 0.35854, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3620 - accuracy: 0.8493 - val_loss: 0.3585 - val_accuracy: 0.8524\n",
      "Epoch 96/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3615 - accuracy: 0.8493\n",
      "Epoch 96: val_loss improved from 0.35854 to 0.35789, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3615 - accuracy: 0.8496 - val_loss: 0.3579 - val_accuracy: 0.8524\n",
      "Epoch 97/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3620 - accuracy: 0.8493\n",
      "Epoch 97: val_loss improved from 0.35789 to 0.35777, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3614 - accuracy: 0.8495 - val_loss: 0.3578 - val_accuracy: 0.8523\n",
      "Epoch 98/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3609 - accuracy: 0.8497\n",
      "Epoch 98: val_loss improved from 0.35777 to 0.35772, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3614 - accuracy: 0.8495 - val_loss: 0.3577 - val_accuracy: 0.8525\n",
      "Epoch 99/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3610 - accuracy: 0.8497\n",
      "Epoch 99: val_loss improved from 0.35772 to 0.35746, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3615 - accuracy: 0.8494 - val_loss: 0.3575 - val_accuracy: 0.8522\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.8497\n",
      "Epoch 100: val_loss improved from 0.35746 to 0.35740, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3613 - accuracy: 0.8497 - val_loss: 0.3574 - val_accuracy: 0.8524\n",
      "Epoch 101/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3598 - accuracy: 0.8505\n",
      "Epoch 101: val_loss did not improve from 0.35740\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3609 - accuracy: 0.8498 - val_loss: 0.3597 - val_accuracy: 0.8517\n",
      "Epoch 102/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3613 - accuracy: 0.8497\n",
      "Epoch 102: val_loss did not improve from 0.35740\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3610 - accuracy: 0.8498 - val_loss: 0.3580 - val_accuracy: 0.8526\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8496\n",
      "Epoch 103: val_loss did not improve from 0.35740\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3610 - accuracy: 0.8496 - val_loss: 0.3583 - val_accuracy: 0.8524\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8495\n",
      "Epoch 104: val_loss improved from 0.35740 to 0.35697, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3608 - accuracy: 0.8495 - val_loss: 0.3570 - val_accuracy: 0.8523\n",
      "Epoch 105/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3607 - accuracy: 0.8499\n",
      "Epoch 105: val_loss did not improve from 0.35697\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3607 - accuracy: 0.8499 - val_loss: 0.3591 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3620 - accuracy: 0.8488\n",
      "Epoch 106: val_loss did not improve from 0.35697\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.8488 - val_loss: 0.3575 - val_accuracy: 0.8526\n",
      "Epoch 107/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3607 - accuracy: 0.8500\n",
      "Epoch 107: val_loss improved from 0.35697 to 0.35655, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3610 - accuracy: 0.8498 - val_loss: 0.3566 - val_accuracy: 0.8528\n",
      "Epoch 108/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3597 - accuracy: 0.8507\n",
      "Epoch 108: val_loss did not improve from 0.35655\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3605 - accuracy: 0.8500 - val_loss: 0.3566 - val_accuracy: 0.8528\n",
      "Epoch 109/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3614 - accuracy: 0.8500\n",
      "Epoch 109: val_loss did not improve from 0.35655\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3605 - accuracy: 0.8501 - val_loss: 0.3573 - val_accuracy: 0.8526\n",
      "Epoch 110/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3605 - accuracy: 0.8498\n",
      "Epoch 110: val_loss improved from 0.35655 to 0.35635, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.8499 - val_loss: 0.3563 - val_accuracy: 0.8526\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3598 - accuracy: 0.8501\n",
      "Epoch 111: val_loss did not improve from 0.35635\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3598 - accuracy: 0.8501 - val_loss: 0.3564 - val_accuracy: 0.8529\n",
      "Epoch 112/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3593 - accuracy: 0.8504\n",
      "Epoch 112: val_loss improved from 0.35635 to 0.35610, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3597 - accuracy: 0.8502 - val_loss: 0.3561 - val_accuracy: 0.8526\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8499\n",
      "Epoch 113: val_loss did not improve from 0.35610\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3603 - accuracy: 0.8499 - val_loss: 0.3571 - val_accuracy: 0.8531\n",
      "Epoch 114/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3598 - accuracy: 0.8500\n",
      "Epoch 114: val_loss improved from 0.35610 to 0.35593, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3608 - accuracy: 0.8496 - val_loss: 0.3559 - val_accuracy: 0.8527\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8496\n",
      "Epoch 115: val_loss did not improve from 0.35593\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3607 - accuracy: 0.8496 - val_loss: 0.3576 - val_accuracy: 0.8523\n",
      "Epoch 116/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3601 - accuracy: 0.8497\n",
      "Epoch 116: val_loss did not improve from 0.35593\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3603 - accuracy: 0.8497 - val_loss: 0.3559 - val_accuracy: 0.8531\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8503\n",
      "Epoch 117: val_loss did not improve from 0.35593\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3593 - accuracy: 0.8503 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8499\n",
      "Epoch 118: val_loss improved from 0.35593 to 0.35553, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3596 - accuracy: 0.8499 - val_loss: 0.3555 - val_accuracy: 0.8530\n",
      "Epoch 119/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3596 - accuracy: 0.8503\n",
      "Epoch 119: val_loss did not improve from 0.35553\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3589 - accuracy: 0.8505 - val_loss: 0.3570 - val_accuracy: 0.8532\n",
      "Epoch 120/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3597 - accuracy: 0.8503\n",
      "Epoch 120: val_loss improved from 0.35553 to 0.35528, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3590 - accuracy: 0.8503 - val_loss: 0.3553 - val_accuracy: 0.8529\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8506\n",
      "Epoch 121: val_loss did not improve from 0.35528\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3593 - accuracy: 0.8506 - val_loss: 0.3559 - val_accuracy: 0.8531\n",
      "Epoch 122/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3588 - accuracy: 0.8503\n",
      "Epoch 122: val_loss did not improve from 0.35528\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3589 - accuracy: 0.8505 - val_loss: 0.3555 - val_accuracy: 0.8532\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8505\n",
      "Epoch 123: val_loss did not improve from 0.35528\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8505 - val_loss: 0.3553 - val_accuracy: 0.8531\n",
      "Epoch 124/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3583 - accuracy: 0.8508\n",
      "Epoch 124: val_loss improved from 0.35528 to 0.35505, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3587 - accuracy: 0.8505 - val_loss: 0.3551 - val_accuracy: 0.8531\n",
      "Epoch 125/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3582 - accuracy: 0.8507\n",
      "Epoch 125: val_loss improved from 0.35505 to 0.35489, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3588 - accuracy: 0.8504 - val_loss: 0.3549 - val_accuracy: 0.8531\n",
      "Epoch 126/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3580 - accuracy: 0.8506\n",
      "Epoch 126: val_loss did not improve from 0.35489\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3583 - accuracy: 0.8506 - val_loss: 0.3550 - val_accuracy: 0.8533\n",
      "Epoch 127/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3586 - accuracy: 0.8508\n",
      "Epoch 127: val_loss improved from 0.35489 to 0.35478, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3588 - accuracy: 0.8507 - val_loss: 0.3548 - val_accuracy: 0.8533\n",
      "Epoch 128/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3593 - accuracy: 0.8504\n",
      "Epoch 128: val_loss did not improve from 0.35478\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3584 - accuracy: 0.8508 - val_loss: 0.3551 - val_accuracy: 0.8530\n",
      "Epoch 129/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3591 - accuracy: 0.8506\n",
      "Epoch 129: val_loss improved from 0.35478 to 0.35458, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3586 - accuracy: 0.8506 - val_loss: 0.3546 - val_accuracy: 0.8534\n",
      "Epoch 130/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3575 - accuracy: 0.8509\n",
      "Epoch 130: val_loss improved from 0.35458 to 0.35456, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3581 - accuracy: 0.8507 - val_loss: 0.3546 - val_accuracy: 0.8535\n",
      "Epoch 131/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3578 - accuracy: 0.8510\n",
      "Epoch 131: val_loss did not improve from 0.35456\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8509 - val_loss: 0.3547 - val_accuracy: 0.8537\n",
      "Epoch 132/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3577 - accuracy: 0.8509\n",
      "Epoch 132: val_loss improved from 0.35456 to 0.35445, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3582 - accuracy: 0.8507 - val_loss: 0.3545 - val_accuracy: 0.8536\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8508\n",
      "Epoch 133: val_loss improved from 0.35445 to 0.35425, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3579 - accuracy: 0.8508 - val_loss: 0.3542 - val_accuracy: 0.8535\n",
      "Epoch 134/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3587 - accuracy: 0.8510\n",
      "Epoch 134: val_loss did not improve from 0.35425\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3578 - accuracy: 0.8512 - val_loss: 0.3546 - val_accuracy: 0.8535\n",
      "Epoch 135/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3591 - accuracy: 0.8502\n",
      "Epoch 135: val_loss did not improve from 0.35425\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3578 - accuracy: 0.8508 - val_loss: 0.3543 - val_accuracy: 0.8538\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3580 - accuracy: 0.8512\n",
      "Epoch 136: val_loss did not improve from 0.35425\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8512 - val_loss: 0.3543 - val_accuracy: 0.8538\n",
      "Epoch 137/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3577 - accuracy: 0.8508\n",
      "Epoch 137: val_loss improved from 0.35425 to 0.35392, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3579 - accuracy: 0.8507 - val_loss: 0.3539 - val_accuracy: 0.8537\n",
      "Epoch 138/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3598 - accuracy: 0.8502\n",
      "Epoch 138: val_loss did not improve from 0.35392\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8509 - val_loss: 0.3546 - val_accuracy: 0.8534\n",
      "Epoch 139/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3582 - accuracy: 0.8503\n",
      "Epoch 139: val_loss did not improve from 0.35392\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3582 - accuracy: 0.8503 - val_loss: 0.3543 - val_accuracy: 0.8533\n",
      "Epoch 140/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3592 - accuracy: 0.8500\n",
      "Epoch 140: val_loss did not improve from 0.35392\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.8501 - val_loss: 0.3548 - val_accuracy: 0.8533\n",
      "Epoch 141/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3588 - accuracy: 0.8503\n",
      "Epoch 141: val_loss did not improve from 0.35392\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3579 - accuracy: 0.8506 - val_loss: 0.3539 - val_accuracy: 0.8539\n",
      "Epoch 142/150\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.3583 - accuracy: 0.8504\n",
      "Epoch 142: val_loss improved from 0.35392 to 0.35359, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3574 - accuracy: 0.8508 - val_loss: 0.3536 - val_accuracy: 0.8539\n",
      "Epoch 143/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3569 - accuracy: 0.8511\n",
      "Epoch 143: val_loss did not improve from 0.35359\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3570 - accuracy: 0.8511 - val_loss: 0.3538 - val_accuracy: 0.8536\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8510\n",
      "Epoch 144: val_loss improved from 0.35359 to 0.35357, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3572 - accuracy: 0.8510 - val_loss: 0.3536 - val_accuracy: 0.8538\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8510\n",
      "Epoch 145: val_loss did not improve from 0.35357\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3571 - accuracy: 0.8510 - val_loss: 0.3546 - val_accuracy: 0.8533\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8511\n",
      "Epoch 146: val_loss improved from 0.35357 to 0.35335, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3571 - accuracy: 0.8511 - val_loss: 0.3533 - val_accuracy: 0.8538\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.8510\n",
      "Epoch 147: val_loss improved from 0.35335 to 0.35323, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3568 - accuracy: 0.8510 - val_loss: 0.3532 - val_accuracy: 0.8539\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8510\n",
      "Epoch 148: val_loss improved from 0.35323 to 0.35320, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3569 - accuracy: 0.8510 - val_loss: 0.3532 - val_accuracy: 0.8542\n",
      "Epoch 149/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.3572 - accuracy: 0.8507\n",
      "Epoch 149: val_loss improved from 0.35320 to 0.35307, saving model to lstm_training\\toptag_model_lstm.h5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3572 - accuracy: 0.8509 - val_loss: 0.3531 - val_accuracy: 0.8541\n",
      "Epoch 150/150\n",
      "15/19 [======================>.......] - ETA: 0s - loss: 0.3561 - accuracy: 0.8518\n",
      "Epoch 150: val_loss did not improve from 0.35307\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3568 - accuracy: 0.8512 - val_loss: 0.3535 - val_accuracy: 0.8538\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=20)\n",
    "adam = Adam(lr = 0.0002)\n",
    "toy_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = toy_lstm.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 2**14,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint('lstm_training/toptag_model_lstm.h5', verbose=1, save_best_only=True), es],\n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b03fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 2s 2ms/step\n",
      "auc score for toy LSTM model is  0.9185016783124074\n"
     ]
    }
   ],
   "source": [
    "# check performance\n",
    "y_keras = toy_lstm.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(\"auc score for toy LSTM model is \", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30964d",
   "metadata": {},
   "source": [
    "(Option 2) Load the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07e3d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the toy model\n",
    "toy_lstm = load_model('lstm_training/toptag_model_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6439da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed6c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 1s 2ms/step\n",
      "auc score for toy LSTM model is  0.9184356018338126\n"
     ]
    }
   ],
   "source": [
    "# check performance\n",
    "y_keras = toy_lstm.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(\"auc score for toy LSTM model is \", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c87f7a",
   "metadata": {},
   "source": [
    "Before doing quantizaion, please go to the [qkeras Github page](https://github.com/google/qkeras/tree/master/qkeras) to **check if the layers in your model have corresponding quantized layer**. This is the most important check before doing quantization since you cannot do quantization with qkeras if qkeras doesn't support the layers in your model to quantize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52cb2a",
   "metadata": {},
   "source": [
    "Qkeras supports quantization for Dense layer, LSTM layer and Relu Activation layer. Therefore we can continue on our quantization process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca13621",
   "metadata": {},
   "source": [
    "Then we need to **check the weight of our toy model before quantization**. This step is really helpful for checking whether you quantized your model correctly or not. I highly suggest you do not skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "848fa29c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 : [array([[ 3.91980559e-01, -1.85346827e-01,  2.45009765e-01,\n",
      "        -1.09824352e-01, -4.83062685e-01,  3.76102507e-01,\n",
      "        -1.70365587e-01,  8.48953724e-02,  4.32299078e-01,\n",
      "        -2.66808450e-01,  6.32572651e-01, -8.31376016e-02,\n",
      "         3.75124812e-01, -6.55259192e-01, -7.90778339e-01,\n",
      "         3.50813866e-01, -2.23879382e-01,  1.52269840e-01,\n",
      "        -1.98121537e-02, -6.61871076e-01],\n",
      "       [ 3.68319333e-01, -7.17377290e-02,  2.27749780e-01,\n",
      "         2.88435400e-01, -3.93797606e-02,  6.05319068e-02,\n",
      "        -2.22660616e-01,  2.93885708e-01,  5.20106405e-03,\n",
      "         2.05316842e-01, -2.75433093e-01,  5.85466981e-01,\n",
      "         1.53533906e-01, -1.45282954e-01,  5.66224039e-01,\n",
      "         9.20868099e-01,  4.61920984e-02, -1.78340644e-01,\n",
      "         2.01875269e-01,  7.31292427e-01],\n",
      "       [ 1.56670883e-01, -1.65241182e-01,  4.82763588e-01,\n",
      "         2.61744499e-01,  1.20619744e-01, -5.83637953e-02,\n",
      "         1.97152123e-01,  1.22151196e-01,  1.34238169e-01,\n",
      "         4.81924146e-01,  5.85940421e-01, -6.35307074e-01,\n",
      "         1.33947164e-01, -9.07446742e-02, -4.16026920e-01,\n",
      "         5.74493885e-01,  4.77119148e-01,  5.33315480e-01,\n",
      "         1.98309813e-02,  9.28494394e-01],\n",
      "       [ 1.80097342e-01,  2.30425209e-01,  1.75607782e-02,\n",
      "         2.13005662e-01, -6.54986918e-01,  1.64881572e-01,\n",
      "        -1.98712245e-01,  5.04505895e-02,  2.95517534e-01,\n",
      "        -3.33093464e-01, -3.24822724e-01, -4.48547363e-01,\n",
      "        -6.44445479e-01, -6.35676906e-02, -8.15738559e-01,\n",
      "         3.34667146e-01, -2.97352169e-02,  1.44803822e-01,\n",
      "         2.27573857e-01, -7.23528743e-01],\n",
      "       [-2.72041245e-04,  1.13421716e-01, -5.33743739e-01,\n",
      "         1.89299491e-04,  6.09875560e-01, -1.87465280e-01,\n",
      "        -1.05316639e-01, -7.70713866e-01, -3.16964865e-01,\n",
      "         3.79699856e-01, -1.09573519e+00, -6.28024220e-01,\n",
      "        -6.61785007e-01, -2.82550722e-01,  9.19105411e-01,\n",
      "        -1.28486869e-03,  1.58710987e-04, -7.13333964e-01,\n",
      "        -7.40090618e-03,  4.10980225e-01],\n",
      "       [ 9.97319221e-02, -1.10129766e-01,  2.76437342e-01,\n",
      "        -5.32373309e-01,  1.58010051e-01, -7.20203593e-02,\n",
      "        -4.64446276e-01, -1.38850719e-01,  2.33397603e-01,\n",
      "         2.83584833e-01, -1.03540383e-01,  2.44350657e-02,\n",
      "         9.23703834e-02, -9.67356414e-02,  4.04183805e-01,\n",
      "        -1.02315344e-01,  5.56716621e-01,  2.83939064e-01,\n",
      "         4.08448040e-01,  3.61212611e-01]], dtype=float32), array([[-0.06957647,  0.05280842,  0.6241559 , -0.6165482 ,  0.92732424,\n",
      "         0.34740847,  0.2329579 , -0.05067281, -0.38753942,  0.331512  ,\n",
      "         0.16301376,  0.09977421,  0.2981232 , -0.19085318,  0.6136243 ,\n",
      "         0.27807292,  0.62785345,  0.631863  ,  0.0218223 , -0.5099771 ],\n",
      "       [-0.07462547,  0.29541802,  0.15303427,  0.6090333 , -0.79532605,\n",
      "        -0.08934832,  0.5583171 , -0.0649083 ,  0.0081115 , -0.8221079 ,\n",
      "         0.03812227,  0.19633102,  0.14572568,  0.11543539, -0.5901937 ,\n",
      "        -0.12367885,  0.26888213, -0.12040389,  0.7804146 , -0.6365118 ],\n",
      "       [ 0.15268867,  0.09548474, -0.31675375,  0.0552168 , -0.4441228 ,\n",
      "         0.01962258,  0.27964202,  0.5426032 , -0.21238364, -0.38856053,\n",
      "         0.38242117,  0.44180372,  0.24311587,  0.23467636, -0.28890058,\n",
      "         0.05348577,  0.11574433,  0.299294  , -0.09286796, -0.11214718],\n",
      "       [-0.8531297 ,  0.5523165 , -0.46683046,  0.47057703,  0.16747676,\n",
      "        -0.5208104 ,  0.5085137 , -0.47954494,  0.23433632, -0.13028708,\n",
      "         0.1665115 ,  0.492276  , -0.04851145,  0.350877  , -0.6641972 ,\n",
      "        -0.25945953,  0.4344967 , -0.12512575,  0.56474495,  0.7636099 ],\n",
      "       [ 0.9214461 ,  0.98735887,  0.14172256,  0.73737264,  0.03985279,\n",
      "         0.2122676 ,  0.2093904 , -0.17389356,  0.91006815,  0.22979109,\n",
      "        -0.0909578 ,  0.19814993, -0.116943  ,  0.33491433,  0.02277117,\n",
      "         0.38382724,  0.8526485 ,  0.24334781,  0.7672746 ,  0.17305472]],\n",
      "      dtype=float32), array([ 0.32676047,  0.15308402,  0.10349999,  0.2720313 , -0.0360462 ,\n",
      "        1.1484083 ,  0.93088025,  1.0896248 ,  1.2127273 ,  1.2278622 ,\n",
      "       -0.06098236,  0.00495392, -0.08368567,  0.01315782,  0.14158861,\n",
      "        0.33089945,  0.2725446 ,  0.09742579,  0.45667365,  0.32938218],\n",
      "      dtype=float32)]\n",
      "layer3 : [array([[-0.7384594 , -0.24387068,  0.26165023, -0.8499145 ,  1.0885285 ],\n",
      "       [-1.2752293 , -0.8486416 ,  1.5523958 ,  0.00844969,  1.034037  ],\n",
      "       [ 0.1889181 , -0.2850323 ,  0.3825203 , -0.32259402,  0.5177435 ],\n",
      "       [-1.2759302 , -0.14605597,  0.16548857, -0.78635514,  1.1438328 ],\n",
      "       [ 1.0275536 ,  0.89729834,  0.45830366,  0.40944475,  0.24971329]],\n",
      "      dtype=float32), array([0.49515453, 0.2945057 , 0.07157164, 0.3455441 , 0.36055687],\n",
      "      dtype=float32)]\n",
      "relu_0 : []\n",
      "layer5 : [array([[ 0.60925484],\n",
      "       [ 0.7051515 ],\n",
      "       [-1.334365  ],\n",
      "       [ 0.64656043],\n",
      "       [-1.537625  ]], dtype=float32), array([0.27615014], dtype=float32)]\n",
      "output_sigmoid : []\n"
     ]
    }
   ],
   "source": [
    "for layer in toy_lstm.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name, \":\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d259fd",
   "metadata": {},
   "source": [
    "After checking the weight of our toy model before quantization, we can finally do our Post-training quantization!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d429c",
   "metadata": {},
   "source": [
    "For doing Post-training quantization, we need to create an paramter \"config\" to tell qkeras how to quantize each layer separately(we don't need to quantize the input layer and the last layer when doing quantization).\n",
    "<br>\n",
    "In this example we quantized each layer with **3 fractional bits, 2 integer bit and 1 sign bits (total of 6 bits)**\n",
    "<br>\n",
    "We always need to go to qkeras source code to check how to quantize different layers. For most of layers we use quantized_bits(bits=8, integer=0, symmetric=0, keep_negative=1) function to quantize, **\"bits\" parameter is the number of total bits for quantization, \"integer\" parameter is number of integer bits for quantization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e730ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_bits = 3\n",
    "int_bits = 2\n",
    "total_bits = frac_bits + int_bits + 1\n",
    "config = {\n",
    "            \"QLSTM\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"bias_quantizer\" : f\"quantized_bits({total_bits}, {int_bits},1)\",\n",
    "                 \"recurrent_quantizer\": f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"state_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"QDense\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                \"bias_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"relu_0\" : f\"quantized_relu({total_bits},{int_bits},1)\"\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615949a2",
   "metadata": {},
   "source": [
    "Then we use the **\"model_quantize\" function** to quantize our toy lstm model\n",
    "<br>\n",
    "For model_quantize(model, quantizer_config, activation_bits, custom_objects=None, transfer_weights=False,  prefer_qadaptiveactivation=False,  enable_bn_folding=False)\n",
    "<br>\n",
    "We specify four parameters here: **mode, quantizer_config, activation_bits, transfer_weights**\n",
    "<br>\n",
    "**\"model\"** is for the keras model we want to quantized; **\"quantizer_config\"** is for the the config we want for our quantization; **\"activation_bits\"** is the number of activation bits ( normally it is the total number of bits we want to quantize); **\"transfer_weights\"** is whether we use the weight from keras model (for post training quantization, we always want to keep the parameter **\"transfer_weights\"** to be **true** since we need the weights from our trained keras model and do quantization base on them) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8638864",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_qlstm_ptq = model_quantize(toy_lstm, config, 6, transfer_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c9ef5",
   "metadata": {},
   "source": [
    "We can also **check the quantize-parameter** we provided to our toy model by printing them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b00bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1) recurrent: quantized_bits(6,2,1,alpha='auto_po2') state: quantized_bits(6,2,1)\n",
      "layer3 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "relu_0\n",
      "layer5 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "output_sigmoid\n"
     ]
    }
   ],
   "source": [
    "for layer in toy_qlstm_ptq.layers:\n",
    "            if hasattr(layer, \"recurrent_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal), \n",
    "                     \"recurrent:\", str(layer.recurrent_quantizer_internal), \"state:\", str(layer.state_quantizer_internal))\n",
    "            elif hasattr(layer, \"kernel_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "            elif hasattr(layer, \"quantized_relu\"):\n",
    "                print(layer.name, \"quantized_relu:\", str(layer.quantizer))\n",
    "            else:\n",
    "                print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dd8d7",
   "metadata": {},
   "source": [
    "To check if we quantized our model successfully, we need to **check the weight for our model after quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d08a589f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer1': {'weights': [array([[ 0.390625 , -0.1875   ,  0.25     , -0.109375 , -0.484375 ,\n",
       "            0.375    , -0.171875 ,  0.09375  ,  0.4375   , -0.265625 ,\n",
       "            0.625    , -0.078125 ,  0.375    , -0.484375 , -0.78125  ,\n",
       "            0.34375  , -0.21875  ,  0.15625  , -0.015625 , -0.65625  ],\n",
       "          [ 0.375    , -0.0703125,  0.234375 ,  0.28125  , -0.046875 ,\n",
       "            0.0625   , -0.21875  ,  0.28125  ,  0.       ,  0.203125 ,\n",
       "           -0.28125  ,  0.484375 ,  0.15625  , -0.140625 ,  0.5625   ,\n",
       "            0.90625  ,  0.046875 , -0.1875   ,  0.203125 ,  0.71875  ],\n",
       "          [ 0.15625  , -0.1640625,  0.484375 ,  0.265625 ,  0.125    ,\n",
       "           -0.0625   ,  0.203125 ,  0.125    ,  0.140625 ,  0.484375 ,\n",
       "            0.59375  , -0.484375 ,  0.140625 , -0.09375  , -0.40625  ,\n",
       "            0.5625   ,  0.484375 ,  0.53125  ,  0.015625 ,  0.9375   ],\n",
       "          [ 0.1875   ,  0.2265625,  0.015625 ,  0.21875  , -0.484375 ,\n",
       "            0.171875 , -0.203125 ,  0.0625   ,  0.296875 , -0.328125 ,\n",
       "           -0.3125   , -0.453125 , -0.484375 , -0.0625   , -0.8125   ,\n",
       "            0.34375  , -0.03125  ,  0.15625  ,  0.234375 , -0.71875  ],\n",
       "          [ 0.       ,  0.1171875, -0.484375 ,  0.       ,  0.484375 ,\n",
       "           -0.1875   , -0.109375 , -0.78125  , -0.3125   ,  0.375    ,\n",
       "           -0.96875  , -0.484375 , -0.484375 , -0.28125  ,  0.90625  ,\n",
       "            0.       ,  0.       , -0.71875  ,  0.       ,  0.40625  ],\n",
       "          [ 0.09375  , -0.109375 ,  0.28125  , -0.484375 ,  0.15625  ,\n",
       "           -0.078125 , -0.46875  , -0.125    ,  0.234375 ,  0.28125  ,\n",
       "           -0.09375  ,  0.03125  ,  0.09375  , -0.09375  ,  0.40625  ,\n",
       "           -0.09375  ,  0.484375 ,  0.28125  ,  0.40625  ,  0.375    ]],\n",
       "         dtype=float32),\n",
       "   array([[-0.0625   ,  0.0625   ,  0.484375 , -0.625    ,  0.9375   ,\n",
       "            0.34375  ,  0.234375 , -0.046875 , -0.375    ,  0.34375  ,\n",
       "            0.15625  ,  0.09375  ,  0.2421875, -0.1875   ,  0.484375 ,\n",
       "            0.28125  ,  0.625    ,  0.484375 ,  0.03125  , -0.5      ],\n",
       "          [-0.0625   ,  0.28125  ,  0.15625  ,  0.59375  , -0.78125  ,\n",
       "           -0.09375  ,  0.484375 , -0.0625   ,  0.       , -0.8125   ,\n",
       "            0.03125  ,  0.203125 ,  0.1484375,  0.109375 , -0.484375 ,\n",
       "           -0.125    ,  0.28125  , -0.125    ,  0.78125  , -0.625    ],\n",
       "          [ 0.15625  ,  0.09375  , -0.3125   ,  0.0625   , -0.4375   ,\n",
       "            0.015625 ,  0.28125  ,  0.484375 , -0.21875  , -0.375    ,\n",
       "            0.375    ,  0.4375   ,  0.2421875,  0.234375 , -0.28125  ,\n",
       "            0.046875 ,  0.125    ,  0.296875 , -0.09375  , -0.125    ],\n",
       "          [-0.84375  ,  0.5625   , -0.46875  ,  0.46875  ,  0.15625  ,\n",
       "           -0.484375 ,  0.484375 , -0.484375 ,  0.21875  , -0.125    ,\n",
       "            0.171875 ,  0.484375 , -0.046875 ,  0.34375  , -0.484375 ,\n",
       "           -0.265625 ,  0.4375   , -0.125    ,  0.5625   ,  0.75     ],\n",
       "          [ 0.90625  ,  0.96875  ,  0.140625 ,  0.75     ,  0.03125  ,\n",
       "            0.21875  ,  0.203125 , -0.171875 ,  0.90625  ,  0.21875  ,\n",
       "           -0.09375  ,  0.203125 , -0.1171875,  0.328125 ,  0.015625 ,\n",
       "            0.390625 ,  0.84375  ,  0.25     ,  0.78125  ,  0.1875   ]],\n",
       "         dtype=float32),\n",
       "   array([ 0.375,  0.125,  0.125,  0.25 ,  0.   ,  1.125,  0.875,  1.125,\n",
       "           1.25 ,  1.25 ,  0.   ,  0.   , -0.125,  0.   ,  0.125,  0.375,\n",
       "           0.25 ,  0.125,  0.5  ,  0.375], dtype=float32)]},\n",
       " 'layer3': {'weights': [array([[-0.75   , -0.25   ,  0.25   , -0.84375,  0.96875],\n",
       "          [-0.96875, -0.84375,  1.5625 ,  0.     ,  0.96875],\n",
       "          [ 0.1875 , -0.28125,  0.375  , -0.3125 ,  0.53125],\n",
       "          [-0.96875, -0.15625,  0.1875 , -0.78125,  0.96875],\n",
       "          [ 0.96875,  0.90625,  0.4375 ,  0.40625,  0.25   ]], dtype=float32),\n",
       "   array([0.5  , 0.25 , 0.125, 0.375, 0.375], dtype=float32)]},\n",
       " 'layer5': {'weights': [array([[ 0.625 ],\n",
       "          [ 0.6875],\n",
       "          [-1.3125],\n",
       "          [ 0.625 ],\n",
       "          [-1.5625]], dtype=float32),\n",
       "   array([0.25], dtype=float32)]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_quantized_weights(toy_qlstm_ptq, \"ptq2int6fra_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff2bd4",
   "metadata": {},
   "source": [
    "By comparing the weight we get after training with the weight we get before training, we can tell that our model has been **successfully quantized**! Great job!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e9472",
   "metadata": {},
   "source": [
    "For the **last step** in our Post-training quantization, we need to check and compare the **AUC score** of our model before quantization and after quantization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfa59cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 41s 64ms/step\n",
      "auc score for toy QLSTM model is  0.782112847008039\n"
     ]
    }
   ],
   "source": [
    "# check performance\n",
    "y_keras = toy_qlstm_ptq.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(\"auc score for toy QLSTM model is \", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdd956",
   "metadata": {},
   "source": [
    "### 2.3: Now is your time to do Post-training quantization to a similiar model!\n",
    "**Hint: check the steps we did in section 2.2 if you don't know how to do it. All the codes in this part can be find with a similiar version in section 2.2**|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a54e4",
   "metadata": {},
   "source": [
    "(Option 1) You can load the toy model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f361b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the toy gru model\n",
    "toy_gru = load_model('gru_training/toptag_model_gru.h5')\n",
    "\n",
    "# load the training data\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261c62b",
   "metadata": {},
   "source": [
    "(Option 2) You can also train the keras model by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9a6adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyihu\\anaconda3\\envs\\hls4ml-tutorial\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "14/19 [=====================>........] - ETA: 0s - loss: 0.7008 - accuracy: 0.5015\n",
      "Epoch 1: val_loss improved from inf to 0.69668, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 2s 45ms/step - loss: 0.7000 - accuracy: 0.5011 - val_loss: 0.6967 - val_accuracy: 0.4995\n",
      "Epoch 2/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6958 - accuracy: 0.4816\n",
      "Epoch 2: val_loss improved from 0.69668 to 0.69491, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6958 - accuracy: 0.4821 - val_loss: 0.6949 - val_accuracy: 0.4986\n",
      "Epoch 3/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6948 - accuracy: 0.4978\n",
      "Epoch 3: val_loss improved from 0.69491 to 0.69465, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6948 - accuracy: 0.4978 - val_loss: 0.6947 - val_accuracy: 0.4996\n",
      "Epoch 4/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6946 - accuracy: 0.5037\n",
      "Epoch 4: val_loss improved from 0.69465 to 0.69441, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6946 - accuracy: 0.5041 - val_loss: 0.6944 - val_accuracy: 0.5207\n",
      "Epoch 5/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6943 - accuracy: 0.5294\n",
      "Epoch 5: val_loss improved from 0.69441 to 0.69412, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6943 - accuracy: 0.5297 - val_loss: 0.6941 - val_accuracy: 0.5414\n",
      "Epoch 6/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6940 - accuracy: 0.5470\n",
      "Epoch 6: val_loss improved from 0.69412 to 0.69377, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6940 - accuracy: 0.5478 - val_loss: 0.6938 - val_accuracy: 0.5537\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5559\n",
      "Epoch 7: val_loss improved from 0.69377 to 0.69332, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6936 - accuracy: 0.5559 - val_loss: 0.6933 - val_accuracy: 0.5606\n",
      "Epoch 8/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5688\n",
      "Epoch 8: val_loss improved from 0.69332 to 0.69274, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5683 - val_loss: 0.6927 - val_accuracy: 0.5602\n",
      "Epoch 9/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.5756\n",
      "Epoch 9: val_loss improved from 0.69274 to 0.69193, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6923 - accuracy: 0.5759 - val_loss: 0.6919 - val_accuracy: 0.5847\n",
      "Epoch 10/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6914 - accuracy: 0.5909\n",
      "Epoch 10: val_loss improved from 0.69193 to 0.69074, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5905 - val_loss: 0.6907 - val_accuracy: 0.6015\n",
      "Epoch 11/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6900 - accuracy: 0.6199\n",
      "Epoch 11: val_loss improved from 0.69074 to 0.68876, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.6210 - val_loss: 0.6888 - val_accuracy: 0.6365\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.6487\n",
      "Epoch 12: val_loss improved from 0.68876 to 0.68483, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6871 - accuracy: 0.6487 - val_loss: 0.6848 - val_accuracy: 0.6665\n",
      "Epoch 13/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.6817 - accuracy: 0.6865\n",
      "Epoch 13: val_loss improved from 0.68483 to 0.67487, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6811 - accuracy: 0.6893 - val_loss: 0.6749 - val_accuracy: 0.7058\n",
      "Epoch 14/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6634 - accuracy: 0.7258\n",
      "Epoch 14: val_loss improved from 0.67487 to 0.64098, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6629 - accuracy: 0.7265 - val_loss: 0.6410 - val_accuracy: 0.7493\n",
      "Epoch 15/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6075 - accuracy: 0.7603\n",
      "Epoch 15: val_loss improved from 0.64098 to 0.56607, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6065 - accuracy: 0.7606 - val_loss: 0.5661 - val_accuracy: 0.7712\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.7704\n",
      "Epoch 16: val_loss improved from 0.56607 to 0.52157, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5451 - accuracy: 0.7704 - val_loss: 0.5216 - val_accuracy: 0.7848\n",
      "Epoch 17/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5054 - accuracy: 0.7905\n",
      "Epoch 17: val_loss improved from 0.52157 to 0.48542, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5046 - accuracy: 0.7911 - val_loss: 0.4854 - val_accuracy: 0.8031\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4719 - accuracy: 0.8055\n",
      "Epoch 18: val_loss improved from 0.48542 to 0.45632, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4719 - accuracy: 0.8055 - val_loss: 0.4563 - val_accuracy: 0.8135\n",
      "Epoch 19/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4485 - accuracy: 0.8165\n",
      "Epoch 19: val_loss improved from 0.45632 to 0.43846, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4484 - accuracy: 0.8165 - val_loss: 0.4385 - val_accuracy: 0.8209\n",
      "Epoch 20/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4330 - accuracy: 0.8236\n",
      "Epoch 20: val_loss improved from 0.43846 to 0.42566, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4329 - accuracy: 0.8236 - val_loss: 0.4257 - val_accuracy: 0.8261\n",
      "Epoch 21/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4239 - accuracy: 0.8278\n",
      "Epoch 21: val_loss improved from 0.42566 to 0.41684, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4226 - accuracy: 0.8283 - val_loss: 0.4168 - val_accuracy: 0.8300\n",
      "Epoch 22/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4156 - accuracy: 0.8304\n",
      "Epoch 22: val_loss improved from 0.41684 to 0.41163, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4157 - accuracy: 0.8304 - val_loss: 0.4116 - val_accuracy: 0.8320\n",
      "Epoch 23/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4104 - accuracy: 0.8331\n",
      "Epoch 23: val_loss improved from 0.41163 to 0.40756, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4109 - accuracy: 0.8328 - val_loss: 0.4076 - val_accuracy: 0.8335\n",
      "Epoch 24/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4072 - accuracy: 0.8343\n",
      "Epoch 24: val_loss improved from 0.40756 to 0.40411, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4075 - accuracy: 0.8339 - val_loss: 0.4041 - val_accuracy: 0.8349\n",
      "Epoch 25/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4054 - accuracy: 0.8346\n",
      "Epoch 25: val_loss improved from 0.40411 to 0.40172, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.8345 - val_loss: 0.4017 - val_accuracy: 0.8355\n",
      "Epoch 26/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4040 - accuracy: 0.8348\n",
      "Epoch 26: val_loss improved from 0.40172 to 0.40001, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.4037 - accuracy: 0.8349 - val_loss: 0.4000 - val_accuracy: 0.8360\n",
      "Epoch 27/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4016 - accuracy: 0.8356\n",
      "Epoch 27: val_loss improved from 0.40001 to 0.39863, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4016 - accuracy: 0.8356 - val_loss: 0.3986 - val_accuracy: 0.8365\n",
      "Epoch 28/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4007 - accuracy: 0.8358\n",
      "Epoch 28: val_loss improved from 0.39863 to 0.39735, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4005 - accuracy: 0.8359 - val_loss: 0.3974 - val_accuracy: 0.8368\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8361\n",
      "Epoch 29: val_loss improved from 0.39735 to 0.39692, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3995 - accuracy: 0.8361 - val_loss: 0.3969 - val_accuracy: 0.8371\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8366\n",
      "Epoch 30: val_loss improved from 0.39692 to 0.39537, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3990 - accuracy: 0.8366 - val_loss: 0.3954 - val_accuracy: 0.8376\n",
      "Epoch 31/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3976 - accuracy: 0.8369\n",
      "Epoch 31: val_loss improved from 0.39537 to 0.39448, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3976 - accuracy: 0.8368 - val_loss: 0.3945 - val_accuracy: 0.8378\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3967 - accuracy: 0.8373\n",
      "Epoch 32: val_loss improved from 0.39448 to 0.39385, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3967 - accuracy: 0.8373 - val_loss: 0.3938 - val_accuracy: 0.8378\n",
      "Epoch 33/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3959 - accuracy: 0.8375\n",
      "Epoch 33: val_loss improved from 0.39385 to 0.39339, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3961 - accuracy: 0.8375 - val_loss: 0.3934 - val_accuracy: 0.8381\n",
      "Epoch 34/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3954 - accuracy: 0.8376\n",
      "Epoch 34: val_loss improved from 0.39339 to 0.39229, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3953 - accuracy: 0.8377 - val_loss: 0.3923 - val_accuracy: 0.8384\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.8378\n",
      "Epoch 35: val_loss did not improve from 0.39229\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3950 - accuracy: 0.8378 - val_loss: 0.3931 - val_accuracy: 0.8382\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8374\n",
      "Epoch 36: val_loss improved from 0.39229 to 0.39207, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3955 - accuracy: 0.8374 - val_loss: 0.3921 - val_accuracy: 0.8383\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.8383\n",
      "Epoch 37: val_loss improved from 0.39207 to 0.39157, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3936 - accuracy: 0.8383 - val_loss: 0.3916 - val_accuracy: 0.8388\n",
      "Epoch 38/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3931 - accuracy: 0.8383\n",
      "Epoch 38: val_loss improved from 0.39157 to 0.38979, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3931 - accuracy: 0.8383 - val_loss: 0.3898 - val_accuracy: 0.8397\n",
      "Epoch 39/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3927 - accuracy: 0.8388\n",
      "Epoch 39: val_loss improved from 0.38979 to 0.38931, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3924 - accuracy: 0.8391 - val_loss: 0.3893 - val_accuracy: 0.8399\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.8391\n",
      "Epoch 40: val_loss improved from 0.38931 to 0.38889, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3919 - accuracy: 0.8391 - val_loss: 0.3889 - val_accuracy: 0.8400\n",
      "Epoch 41/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3912 - accuracy: 0.8394\n",
      "Epoch 41: val_loss improved from 0.38889 to 0.38831, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3914 - accuracy: 0.8394 - val_loss: 0.3883 - val_accuracy: 0.8404\n",
      "Epoch 42/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3913 - accuracy: 0.8392\n",
      "Epoch 42: val_loss did not improve from 0.38831\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8394 - val_loss: 0.3885 - val_accuracy: 0.8399\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.8397\n",
      "Epoch 43: val_loss improved from 0.38831 to 0.38749, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.8397 - val_loss: 0.3875 - val_accuracy: 0.8407\n",
      "Epoch 44/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3908 - accuracy: 0.8395\n",
      "Epoch 44: val_loss improved from 0.38749 to 0.38712, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.8395 - val_loss: 0.3871 - val_accuracy: 0.8408\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8398\n",
      "Epoch 45: val_loss improved from 0.38712 to 0.38669, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3902 - accuracy: 0.8398 - val_loss: 0.3867 - val_accuracy: 0.8412\n",
      "Epoch 46/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3896 - accuracy: 0.8400\n",
      "Epoch 46: val_loss did not improve from 0.38669\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8400 - val_loss: 0.3881 - val_accuracy: 0.8402\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8398\n",
      "Epoch 47: val_loss improved from 0.38669 to 0.38603, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3900 - accuracy: 0.8398 - val_loss: 0.3860 - val_accuracy: 0.8413\n",
      "Epoch 48/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3892 - accuracy: 0.8405\n",
      "Epoch 48: val_loss did not improve from 0.38603\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3891 - accuracy: 0.8405 - val_loss: 0.3863 - val_accuracy: 0.8410\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.8402\n",
      "Epoch 49: val_loss improved from 0.38603 to 0.38542, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3886 - accuracy: 0.8402 - val_loss: 0.3854 - val_accuracy: 0.8417\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8403\n",
      "Epoch 50: val_loss improved from 0.38542 to 0.38523, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3883 - accuracy: 0.8403 - val_loss: 0.3852 - val_accuracy: 0.8415\n",
      "Epoch 51/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3888 - accuracy: 0.8402\n",
      "Epoch 51: val_loss improved from 0.38523 to 0.38483, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3881 - accuracy: 0.8405 - val_loss: 0.3848 - val_accuracy: 0.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3878 - accuracy: 0.8406\n",
      "Epoch 52: val_loss improved from 0.38483 to 0.38458, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3878 - accuracy: 0.8406 - val_loss: 0.3846 - val_accuracy: 0.8419\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8408\n",
      "Epoch 53: val_loss did not improve from 0.38458\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3875 - accuracy: 0.8408 - val_loss: 0.3846 - val_accuracy: 0.8416\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8409\n",
      "Epoch 54: val_loss improved from 0.38458 to 0.38409, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3873 - accuracy: 0.8409 - val_loss: 0.3841 - val_accuracy: 0.8420\n",
      "Epoch 55/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3868 - accuracy: 0.8411\n",
      "Epoch 55: val_loss improved from 0.38409 to 0.38398, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3871 - accuracy: 0.8410 - val_loss: 0.3840 - val_accuracy: 0.8418\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8407\n",
      "Epoch 56: val_loss improved from 0.38398 to 0.38370, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3871 - accuracy: 0.8407 - val_loss: 0.3837 - val_accuracy: 0.8421\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8408\n",
      "Epoch 57: val_loss improved from 0.38370 to 0.38344, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3866 - accuracy: 0.8408 - val_loss: 0.3834 - val_accuracy: 0.8420\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8410\n",
      "Epoch 58: val_loss improved from 0.38344 to 0.38343, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3866 - accuracy: 0.8410 - val_loss: 0.3834 - val_accuracy: 0.8421\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8406\n",
      "Epoch 59: val_loss improved from 0.38343 to 0.38322, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3869 - accuracy: 0.8406 - val_loss: 0.3832 - val_accuracy: 0.8423\n",
      "Epoch 60/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3867 - accuracy: 0.8407\n",
      "Epoch 60: val_loss improved from 0.38322 to 0.38298, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3866 - accuracy: 0.8408 - val_loss: 0.3830 - val_accuracy: 0.8422\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8408\n",
      "Epoch 61: val_loss improved from 0.38298 to 0.38277, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3863 - accuracy: 0.8408 - val_loss: 0.3828 - val_accuracy: 0.8423\n",
      "Epoch 62/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3860 - accuracy: 0.8411\n",
      "Epoch 62: val_loss improved from 0.38277 to 0.38236, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3859 - accuracy: 0.8412 - val_loss: 0.3824 - val_accuracy: 0.8426\n",
      "Epoch 63/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3853 - accuracy: 0.8414\n",
      "Epoch 63: val_loss did not improve from 0.38236\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.8412 - val_loss: 0.3825 - val_accuracy: 0.8424\n",
      "Epoch 64/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3857 - accuracy: 0.8412\n",
      "Epoch 64: val_loss improved from 0.38236 to 0.38213, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3856 - accuracy: 0.8413 - val_loss: 0.3821 - val_accuracy: 0.8428\n",
      "Epoch 65/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3851 - accuracy: 0.8413\n",
      "Epoch 65: val_loss improved from 0.38213 to 0.38180, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3850 - accuracy: 0.8413 - val_loss: 0.3818 - val_accuracy: 0.8427\n",
      "Epoch 66/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3848 - accuracy: 0.8414\n",
      "Epoch 66: val_loss improved from 0.38180 to 0.38180, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3849 - accuracy: 0.8415 - val_loss: 0.3818 - val_accuracy: 0.8431\n",
      "Epoch 67/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3845 - accuracy: 0.8416\n",
      "Epoch 67: val_loss did not improve from 0.38180\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3847 - accuracy: 0.8414 - val_loss: 0.3819 - val_accuracy: 0.8426\n",
      "Epoch 68/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3846 - accuracy: 0.8415\n",
      "Epoch 68: val_loss improved from 0.38180 to 0.38120, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3845 - accuracy: 0.8415 - val_loss: 0.3812 - val_accuracy: 0.8428\n",
      "Epoch 69/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3842 - accuracy: 0.8419\n",
      "Epoch 69: val_loss improved from 0.38120 to 0.38115, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3844 - accuracy: 0.8417 - val_loss: 0.3812 - val_accuracy: 0.8432\n",
      "Epoch 70/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3841 - accuracy: 0.8416\n",
      "Epoch 70: val_loss did not improve from 0.38115\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8415 - val_loss: 0.3812 - val_accuracy: 0.8426\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8415\n",
      "Epoch 71: val_loss did not improve from 0.38115\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8415 - val_loss: 0.3817 - val_accuracy: 0.8425\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8415\n",
      "Epoch 72: val_loss did not improve from 0.38115\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3841 - accuracy: 0.8415 - val_loss: 0.3815 - val_accuracy: 0.8426\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8410\n",
      "Epoch 73: val_loss did not improve from 0.38115\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8410 - val_loss: 0.3812 - val_accuracy: 0.8424\n",
      "Epoch 74/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3838 - accuracy: 0.8414\n",
      "Epoch 74: val_loss improved from 0.38115 to 0.38046, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3837 - accuracy: 0.8416 - val_loss: 0.3805 - val_accuracy: 0.8429\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8417\n",
      "Epoch 75: val_loss improved from 0.38046 to 0.38026, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3835 - accuracy: 0.8417 - val_loss: 0.3803 - val_accuracy: 0.8436\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8416\n",
      "Epoch 76: val_loss did not improve from 0.38026\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3837 - accuracy: 0.8416 - val_loss: 0.3810 - val_accuracy: 0.8426\n",
      "Epoch 77/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3831 - accuracy: 0.8419\n",
      "Epoch 77: val_loss improved from 0.38026 to 0.37988, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3833 - accuracy: 0.8418 - val_loss: 0.3799 - val_accuracy: 0.8432\n",
      "Epoch 78/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3829 - accuracy: 0.8419\n",
      "Epoch 78: val_loss improved from 0.37988 to 0.37956, saving model to gru_training\\toptag_model_gru.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3830 - accuracy: 0.8419 - val_loss: 0.3796 - val_accuracy: 0.8433\n",
      "Epoch 79/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3824 - accuracy: 0.8422\n",
      "Epoch 79: val_loss improved from 0.37956 to 0.37943, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3828 - accuracy: 0.8419 - val_loss: 0.3794 - val_accuracy: 0.8434\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8419\n",
      "Epoch 80: val_loss improved from 0.37943 to 0.37915, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3826 - accuracy: 0.8419 - val_loss: 0.3792 - val_accuracy: 0.8433\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8418\n",
      "Epoch 81: val_loss did not improve from 0.37915\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3828 - accuracy: 0.8418 - val_loss: 0.3813 - val_accuracy: 0.8423\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8416\n",
      "Epoch 82: val_loss improved from 0.37915 to 0.37905, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.8416 - val_loss: 0.3790 - val_accuracy: 0.8433\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8420\n",
      "Epoch 83: val_loss did not improve from 0.37905\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3822 - accuracy: 0.8420 - val_loss: 0.3803 - val_accuracy: 0.8427\n",
      "Epoch 84/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3828 - accuracy: 0.8418\n",
      "Epoch 84: val_loss did not improve from 0.37905\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3824 - accuracy: 0.8419 - val_loss: 0.3799 - val_accuracy: 0.8435\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8420\n",
      "Epoch 85: val_loss improved from 0.37905 to 0.37848, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3821 - accuracy: 0.8420 - val_loss: 0.3785 - val_accuracy: 0.8435\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8421\n",
      "Epoch 86: val_loss improved from 0.37848 to 0.37840, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.8421 - val_loss: 0.3784 - val_accuracy: 0.8434\n",
      "Epoch 87/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3818 - accuracy: 0.8421\n",
      "Epoch 87: val_loss did not improve from 0.37840\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3819 - accuracy: 0.8420 - val_loss: 0.3793 - val_accuracy: 0.8429\n",
      "Epoch 88/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3815 - accuracy: 0.8423\n",
      "Epoch 88: val_loss improved from 0.37840 to 0.37799, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3816 - accuracy: 0.8422 - val_loss: 0.3780 - val_accuracy: 0.8439\n",
      "Epoch 89/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3811 - accuracy: 0.8423\n",
      "Epoch 89: val_loss did not improve from 0.37799\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3812 - accuracy: 0.8422 - val_loss: 0.3782 - val_accuracy: 0.8441\n",
      "Epoch 90/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3810 - accuracy: 0.8423\n",
      "Epoch 90: val_loss improved from 0.37799 to 0.37785, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.8423 - val_loss: 0.3779 - val_accuracy: 0.8435\n",
      "Epoch 91/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3808 - accuracy: 0.8427\n",
      "Epoch 91: val_loss improved from 0.37785 to 0.37767, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.8422 - val_loss: 0.3777 - val_accuracy: 0.8439\n",
      "Epoch 92/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3811 - accuracy: 0.8422\n",
      "Epoch 92: val_loss did not improve from 0.37767\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3809 - accuracy: 0.8423 - val_loss: 0.3779 - val_accuracy: 0.8435\n",
      "Epoch 93/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3812 - accuracy: 0.8421\n",
      "Epoch 93: val_loss improved from 0.37767 to 0.37766, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3809 - accuracy: 0.8422 - val_loss: 0.3777 - val_accuracy: 0.8436\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8424\n",
      "Epoch 94: val_loss improved from 0.37766 to 0.37721, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3806 - accuracy: 0.8424 - val_loss: 0.3772 - val_accuracy: 0.8440\n",
      "Epoch 95/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3805 - accuracy: 0.8427\n",
      "Epoch 95: val_loss improved from 0.37721 to 0.37699, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3804 - accuracy: 0.8428 - val_loss: 0.3770 - val_accuracy: 0.8437\n",
      "Epoch 96/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3803 - accuracy: 0.8426\n",
      "Epoch 96: val_loss did not improve from 0.37699\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.8426 - val_loss: 0.3771 - val_accuracy: 0.8438\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8424\n",
      "Epoch 97: val_loss improved from 0.37699 to 0.37690, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3804 - accuracy: 0.8424 - val_loss: 0.3769 - val_accuracy: 0.8439\n",
      "Epoch 98/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3800 - accuracy: 0.8423\n",
      "Epoch 98: val_loss did not improve from 0.37690\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3802 - accuracy: 0.8424 - val_loss: 0.3781 - val_accuracy: 0.8431\n",
      "Epoch 99/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3807 - accuracy: 0.8421\n",
      "Epoch 99: val_loss improved from 0.37690 to 0.37647, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.8423 - val_loss: 0.3765 - val_accuracy: 0.8441\n",
      "Epoch 100/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3799 - accuracy: 0.8424\n",
      "Epoch 100: val_loss did not improve from 0.37647\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3802 - accuracy: 0.8424 - val_loss: 0.3771 - val_accuracy: 0.8441\n",
      "Epoch 101/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3801 - accuracy: 0.8422\n",
      "Epoch 101: val_loss did not improve from 0.37647\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3803 - accuracy: 0.8421 - val_loss: 0.3767 - val_accuracy: 0.8442\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8424\n",
      "Epoch 102: val_loss did not improve from 0.37647\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3802 - accuracy: 0.8424 - val_loss: 0.3780 - val_accuracy: 0.8435\n",
      "Epoch 103/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3799 - accuracy: 0.8422\n",
      "Epoch 103: val_loss improved from 0.37647 to 0.37632, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3798 - accuracy: 0.8423 - val_loss: 0.3763 - val_accuracy: 0.8441\n",
      "Epoch 104/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3797 - accuracy: 0.8425\n",
      "Epoch 104: val_loss improved from 0.37632 to 0.37627, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3795 - accuracy: 0.8426 - val_loss: 0.3763 - val_accuracy: 0.8441\n",
      "Epoch 105/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3793 - accuracy: 0.8427\n",
      "Epoch 105: val_loss did not improve from 0.37627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3792 - accuracy: 0.8428 - val_loss: 0.3764 - val_accuracy: 0.8439\n",
      "Epoch 106/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3791 - accuracy: 0.8429\n",
      "Epoch 106: val_loss improved from 0.37627 to 0.37563, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.8427 - val_loss: 0.3756 - val_accuracy: 0.8441\n",
      "Epoch 107/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3790 - accuracy: 0.8425\n",
      "Epoch 107: val_loss improved from 0.37563 to 0.37556, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3793 - accuracy: 0.8424 - val_loss: 0.3756 - val_accuracy: 0.8441\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8428\n",
      "Epoch 108: val_loss improved from 0.37556 to 0.37540, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3789 - accuracy: 0.8428 - val_loss: 0.3754 - val_accuracy: 0.8441\n",
      "Epoch 109/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3785 - accuracy: 0.8429\n",
      "Epoch 109: val_loss improved from 0.37540 to 0.37530, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3787 - accuracy: 0.8428 - val_loss: 0.3753 - val_accuracy: 0.8444\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8429\n",
      "Epoch 110: val_loss did not improve from 0.37530\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3787 - accuracy: 0.8429 - val_loss: 0.3758 - val_accuracy: 0.8436\n",
      "Epoch 111/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3787 - accuracy: 0.8429\n",
      "Epoch 111: val_loss improved from 0.37530 to 0.37501, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3786 - accuracy: 0.8429 - val_loss: 0.3750 - val_accuracy: 0.8445\n",
      "Epoch 112/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3786 - accuracy: 0.8426\n",
      "Epoch 112: val_loss did not improve from 0.37501\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 0.8427 - val_loss: 0.3752 - val_accuracy: 0.8445\n",
      "Epoch 113/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3784 - accuracy: 0.8430\n",
      "Epoch 113: val_loss did not improve from 0.37501\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 0.8428 - val_loss: 0.3755 - val_accuracy: 0.8439\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8427\n",
      "Epoch 114: val_loss improved from 0.37501 to 0.37478, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3785 - accuracy: 0.8427 - val_loss: 0.3748 - val_accuracy: 0.8442\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8428\n",
      "Epoch 115: val_loss improved from 0.37478 to 0.37474, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3782 - accuracy: 0.8428 - val_loss: 0.3747 - val_accuracy: 0.8444\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8427\n",
      "Epoch 116: val_loss improved from 0.37474 to 0.37466, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3786 - accuracy: 0.8427 - val_loss: 0.3747 - val_accuracy: 0.8443\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8432\n",
      "Epoch 117: val_loss improved from 0.37466 to 0.37447, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3779 - accuracy: 0.8432 - val_loss: 0.3745 - val_accuracy: 0.8443\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8430\n",
      "Epoch 118: val_loss improved from 0.37447 to 0.37436, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3779 - accuracy: 0.8430 - val_loss: 0.3744 - val_accuracy: 0.8444\n",
      "Epoch 119/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3784 - accuracy: 0.8430\n",
      "Epoch 119: val_loss improved from 0.37436 to 0.37415, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3780 - accuracy: 0.8431 - val_loss: 0.3742 - val_accuracy: 0.8444\n",
      "Epoch 120/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3775 - accuracy: 0.8430\n",
      "Epoch 120: val_loss did not improve from 0.37415\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.8430 - val_loss: 0.3746 - val_accuracy: 0.8448\n",
      "Epoch 121/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3778 - accuracy: 0.8428\n",
      "Epoch 121: val_loss did not improve from 0.37415\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3777 - accuracy: 0.8428 - val_loss: 0.3747 - val_accuracy: 0.8447\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8429\n",
      "Epoch 122: val_loss did not improve from 0.37415\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3780 - accuracy: 0.8429 - val_loss: 0.3751 - val_accuracy: 0.8448\n",
      "Epoch 123/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3778 - accuracy: 0.8432\n",
      "Epoch 123: val_loss did not improve from 0.37415\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3777 - accuracy: 0.8431 - val_loss: 0.3754 - val_accuracy: 0.8448\n",
      "Epoch 124/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3788 - accuracy: 0.8423\n",
      "Epoch 124: val_loss improved from 0.37415 to 0.37379, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3787 - accuracy: 0.8424 - val_loss: 0.3738 - val_accuracy: 0.8447\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8432\n",
      "Epoch 125: val_loss did not improve from 0.37379\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3780 - accuracy: 0.8432 - val_loss: 0.3739 - val_accuracy: 0.8451\n",
      "Epoch 126/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3779 - accuracy: 0.8429\n",
      "Epoch 126: val_loss improved from 0.37379 to 0.37354, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3778 - accuracy: 0.8430 - val_loss: 0.3735 - val_accuracy: 0.8449\n",
      "Epoch 127/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3781 - accuracy: 0.8431\n",
      "Epoch 127: val_loss did not improve from 0.37354\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3776 - accuracy: 0.8432 - val_loss: 0.3742 - val_accuracy: 0.8450\n",
      "Epoch 128/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3770 - accuracy: 0.8433\n",
      "Epoch 128: val_loss did not improve from 0.37354\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8433 - val_loss: 0.3739 - val_accuracy: 0.8452\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.8436\n",
      "Epoch 129: val_loss did not improve from 0.37354\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8436 - val_loss: 0.3740 - val_accuracy: 0.8453\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8433\n",
      "Epoch 130: val_loss improved from 0.37354 to 0.37321, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3769 - accuracy: 0.8433 - val_loss: 0.3732 - val_accuracy: 0.8451\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8435\n",
      "Epoch 131: val_loss improved from 0.37321 to 0.37305, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3768 - accuracy: 0.8435 - val_loss: 0.3730 - val_accuracy: 0.8450\n",
      "Epoch 132/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3766 - accuracy: 0.8434\n",
      "Epoch 132: val_loss improved from 0.37305 to 0.37296, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3766 - accuracy: 0.8434 - val_loss: 0.3730 - val_accuracy: 0.8451\n",
      "Epoch 133/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3764 - accuracy: 0.8434\n",
      "Epoch 133: val_loss improved from 0.37296 to 0.37289, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3764 - accuracy: 0.8435 - val_loss: 0.3729 - val_accuracy: 0.8453\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.8435\n",
      "Epoch 134: val_loss improved from 0.37289 to 0.37274, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3763 - accuracy: 0.8435 - val_loss: 0.3727 - val_accuracy: 0.8453\n",
      "Epoch 135/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3762 - accuracy: 0.8435\n",
      "Epoch 135: val_loss improved from 0.37274 to 0.37273, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3762 - accuracy: 0.8435 - val_loss: 0.3727 - val_accuracy: 0.8450\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8437\n",
      "Epoch 136: val_loss improved from 0.37273 to 0.37257, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3762 - accuracy: 0.8437 - val_loss: 0.3726 - val_accuracy: 0.8453\n",
      "Epoch 137/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3763 - accuracy: 0.8435\n",
      "Epoch 137: val_loss did not improve from 0.37257\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3760 - accuracy: 0.8437 - val_loss: 0.3731 - val_accuracy: 0.8455\n",
      "Epoch 138/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3761 - accuracy: 0.8438\n",
      "Epoch 138: val_loss did not improve from 0.37257\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8437 - val_loss: 0.3728 - val_accuracy: 0.8458\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.8435\n",
      "Epoch 139: val_loss improved from 0.37257 to 0.37215, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.3765 - accuracy: 0.8435 - val_loss: 0.3722 - val_accuracy: 0.8454\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8436\n",
      "Epoch 140: val_loss did not improve from 0.37215\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3762 - accuracy: 0.8436 - val_loss: 0.3722 - val_accuracy: 0.8458\n",
      "Epoch 141/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3760 - accuracy: 0.8435\n",
      "Epoch 141: val_loss improved from 0.37215 to 0.37211, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.8437 - val_loss: 0.3721 - val_accuracy: 0.8457\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.8437\n",
      "Epoch 142: val_loss did not improve from 0.37211\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3757 - accuracy: 0.8437 - val_loss: 0.3722 - val_accuracy: 0.8460\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.8437\n",
      "Epoch 143: val_loss improved from 0.37211 to 0.37208, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.8437 - val_loss: 0.3721 - val_accuracy: 0.8456\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3754 - accuracy: 0.8438\n",
      "Epoch 144: val_loss improved from 0.37208 to 0.37200, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3754 - accuracy: 0.8438 - val_loss: 0.3720 - val_accuracy: 0.8459\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8440\n",
      "Epoch 145: val_loss improved from 0.37200 to 0.37182, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8440 - val_loss: 0.3718 - val_accuracy: 0.8458\n",
      "Epoch 146/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3751 - accuracy: 0.8442\n",
      "Epoch 146: val_loss did not improve from 0.37182\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.8439 - val_loss: 0.3735 - val_accuracy: 0.8455\n",
      "Epoch 147/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3758 - accuracy: 0.8437\n",
      "Epoch 147: val_loss improved from 0.37182 to 0.37125, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3754 - accuracy: 0.8440 - val_loss: 0.3712 - val_accuracy: 0.8464\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8440\n",
      "Epoch 148: val_loss improved from 0.37125 to 0.37114, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3748 - accuracy: 0.8440 - val_loss: 0.3711 - val_accuracy: 0.8462\n",
      "Epoch 149/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3748 - accuracy: 0.8442\n",
      "Epoch 149: val_loss improved from 0.37114 to 0.37103, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3747 - accuracy: 0.8442 - val_loss: 0.3710 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8442\n",
      "Epoch 150: val_loss improved from 0.37103 to 0.37087, saving model to gru_training\\toptag_model_gru.h5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.8442 - val_loss: 0.3709 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "x_train = np.load('./x_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "y_train = y_train[:,4:5]\n",
    "\n",
    "# load testing data\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')\n",
    "\n",
    "# create the gru model\n",
    "toy_gru = Sequential()\n",
    "toy_gru.add(GRU(5, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "               name = 'layer1', input_shape = (20,6)))\n",
    "toy_gru.add(Dense(5, kernel_initializer='glorot_normal', name='layer3'))\n",
    "toy_gru.add(Activation('relu', name = 'relu_0'))\n",
    "toy_gru.add(Dense(1, name = 'layer5'))\n",
    "toy_gru.add(Activation('sigmoid', name = 'output_sigmoid'))\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=20)\n",
    "adam = Adam(lr = 0.0002)\n",
    "toy_gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = toy_gru.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 2**14,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint('gru_training/toptag_model_gru.h5', verbose=1, save_best_only=True), es],\n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7238e",
   "metadata": {},
   "source": [
    "The model we are using is another toptag model with one **GRU** layer.\n",
    "<br>\n",
    "Here you can see what the model looks like and check the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "533098c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (GRU)                (None, 5)                 195       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 5)                 30        \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 5)                 0         \n",
      "                                                                 \n",
      " layer5 (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "toy_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0470a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 1s 2ms/step\n",
      "auc score for toy GRU model is  0.907753904421434\n"
     ]
    }
   ],
   "source": [
    "# Check the AUC score\n",
    "y_keras = toy_gru.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(\"auc score for toy GRU model is \", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7059a9",
   "metadata": {},
   "source": [
    "Don't forget to **check your model's weight before quantization** (Hint: use \"layer.get_weights()\" to get the value of weights for each layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aa4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the weight for our keras model\n",
    "for layer in toy_gru.layers:\n",
    "    # Replace this line with your own code\n",
    "    # Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8659a",
   "metadata": {},
   "source": [
    "Write the **\"config\"** for applying quantization to our model\n",
    "<br>\n",
    "Here we also want to quantize this model to **3 fractional bits, 2 integer bits, 1 sign bits (6 bits in total)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_bits = 3\n",
    "int_bits = 2\n",
    "total_bits = frac_bits + int_bits + 1\n",
    "\n",
    "config = {\n",
    "    # give quantize-paramter to GRU layer\n",
    "    \"QGRU\":{\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "    },\n",
    "    # give quantize-paramter to all two Dense layer\n",
    "    \"QDense\":{\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "    },\n",
    "    # give quantizate-paramter to the relu Activation layer\n",
    "    \"relu_0\" : # Replace this line with your own code\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b14105",
   "metadata": {},
   "source": [
    "Use the **\"model_quantize\"** function to quantize our toy lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_qgru_ptq = model_quantize(#the keras model we want to quantize,\n",
    "                              #the config we want for our quantization,\n",
    "                              #the total number of bits we want to quantize,\n",
    "                              #whether you want transfer_weights to be true or false\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d8d0f",
   "metadata": {},
   "source": [
    "Check the quantize-parameter (Already implemented, you just need to run this code for checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in toy_qgru_ptq.layers:\n",
    "            if hasattr(layer, \"recurrent_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal), \n",
    "                     \"recurrent:\", str(layer.recurrent_quantizer_internal), \"state:\", str(layer.state_quantizer_internal))\n",
    "            elif hasattr(layer, \"kernel_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "            elif hasattr(layer, \"quantized_relu\"):\n",
    "                print(layer.name, \"quantized_relu:\", str(layer.quantizer))\n",
    "            else:\n",
    "                print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6859a51",
   "metadata": {},
   "source": [
    "Check the **weight** for our quantized model (Hint: use \"model_save_quantized_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0ee30",
   "metadata": {},
   "source": [
    "Check the **AUC score** for the quantized model (Hine: use roc_auc_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d03dfe",
   "metadata": {},
   "source": [
    "## Section 3: Quantization Aware Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae16f7",
   "metadata": {},
   "source": [
    "### 3.1 What is Quantization aware training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c7aea",
   "metadata": {},
   "source": [
    "Quantization aware training emulates inference-time quantization, creating a model that downstream tools will use to produce actually quantized models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932064ff",
   "metadata": {},
   "source": [
    "### 3.2 What is the difference between quantization aware training and post-training quantization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711cc7b",
   "metadata": {},
   "source": [
    "When doing post-training quantization, we quantized an already trained model into quantized model. However, in quantization aware training, we quantized the model before training. **Therefore the accuracy for quantization aware training are significantly better than the accuracy for post-training quantization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54e569",
   "metadata": {},
   "source": [
    "### 3.3 How to do quantization aware training with qkeras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04301a",
   "metadata": {},
   "source": [
    "Remember we talked in **Section 3.2** that quantization aware training means doing quantization before training the model. Therefore we don't need to load any already trainined model here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996e324",
   "metadata": {},
   "source": [
    "The toy model we are using is the toptag model with one **GRU** layer we used in **Section 2.3**.\n",
    "<br>\n",
    "Before starting your quantization you need to know what your model looks like.\n",
    "<br>\n",
    "**model.summary()** is a great method in keras that you will use frequently to check the layers in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53b24f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (GRU)                (None, 5)                 195       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 5)                 30        \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 5)                 0         \n",
      "                                                                 \n",
      " layer5 (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "toy_gru = Sequential()\n",
    "toy_gru.add(GRU(5, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "               name = 'layer1', input_shape = (20,6)))\n",
    "toy_gru.add(Dense(5, kernel_initializer='glorot_normal', name='layer3'))\n",
    "toy_gru.add(Activation('relu', name = 'relu_0'))\n",
    "toy_gru.add(Dense(1, name = 'layer5'))\n",
    "toy_gru.add(Activation('sigmoid', name = 'output_sigmoid'))\n",
    "\n",
    "toy_gru.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fc623",
   "metadata": {},
   "source": [
    "We also need to **load the training and testing data** since we need to trian our model this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a63a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "x_train = np.load('./x_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "y_train = y_train[:,4:5]\n",
    "\n",
    "# load the testing data\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee9a76",
   "metadata": {},
   "source": [
    "Before doing quantizaion, please go to the [qkeras Github page](https://github.com/google/qkeras/tree/master/qkeras) to check **if the layers in your model have cooresponding quantized layer**. This is the most important check before doing quantization since you cannot do quantization with qkeras if qkeras doesn't support the layers in your model to quantize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a88d0e",
   "metadata": {},
   "source": [
    "Qkeras supports quantization for **Dense layer, LSTM layer and Relu Activation layer**. Therefore we can continue on our quantization process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc994146",
   "metadata": {},
   "source": [
    "For doing Quantization aware training, we need to create a **\"config\"** to quantize each layer separately(we don't need to quantize the input layer and the last layer when doing quantization, and we don't have a input layer for this specific toptag model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba9c0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_bits = 3\n",
    "int_bits = 2\n",
    "total_bits = frac_bits + int_bits + 1\n",
    "config = {\n",
    "            \"QGRU\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"bias_quantizer\" : f\"quantized_bits({total_bits}, {int_bits},1)\",\n",
    "                 \"recurrent_quantizer\": f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"state_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"QDense\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                \"bias_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"relu_0\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abef96",
   "metadata": {},
   "source": [
    "Then we use **model_quantize()** to quantize our model and use **model.summary()** to check whether our layer is quantized as we expected.\n",
    "<br>\n",
    "For model_quantize(model, quantizer_config, activation_bits, custom_objects=None, transfer_weights=False,  prefer_qadaptiveactivation=False,  enable_bn_folding=False)\n",
    "<br>\n",
    "We specify four parameters here: **mode, quantizer_config, activation_bits, transfer_weights**\n",
    "<br>\n",
    "**\"model\"** is for the keras model we want to quantized; **\"quantizer_config\"** is for the the config we want for our quantization; **\"activation_bits\"** is the number of activation bits ( normally it is the total number of bits we want to quantize); **\"transfer_weights\"** is whether we use the weight from keras model (for quantization aware training, we always want to keep the parameter **\"transfer_weights\"** to be **false** since we will train the model and get its own weights after we quantized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4c0f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (QGRU)               (None, 5)                 195       \n",
      "                                                                 \n",
      " layer3 (QDense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " relu_0 (QActivation)        (None, 5)                 0         \n",
      "                                                                 \n",
      " layer5 (QDense)             (None, 1)                 6         \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "toy_qgru_qat = model_quantize(toy_gru, config, total_bits, transfer_weights=False)\n",
    "toy_qgru_qat.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c9443",
   "metadata": {},
   "source": [
    "We can also check the **quantize-parameter** we provided to our toy model by printing them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dff12bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1) recurrent: quantized_bits(6,2,1,alpha='auto_po2') state: quantized_bits(6,2,1)\n",
      "layer3 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "relu_0\n",
      "layer5 kernel: quantized_bits(6,2,1,alpha='auto_po2') bias: quantized_bits(6,2,1)\n",
      "output_sigmoid\n"
     ]
    }
   ],
   "source": [
    "for layer in toy_qgru_qat.layers:\n",
    "            if hasattr(layer, \"recurrent_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal), \n",
    "                     \"recurrent:\", str(layer.recurrent_quantizer_internal), \"state:\", str(layer.state_quantizer_internal))\n",
    "            elif hasattr(layer, \"kernel_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "            elif hasattr(layer, \"quantized_relu\"):\n",
    "                print(layer.name, \"quantized_relu:\", str(layer.quantizer))\n",
    "            else:\n",
    "                print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e5660",
   "metadata": {},
   "source": [
    "Now it is the time to train our quantized model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25c8821b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyihu\\anaconda3\\envs\\hls4ml-tutorial\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.5010\n",
      "Epoch 1: val_loss improved from inf to 0.69870, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 8s 225ms/step - loss: 0.7019 - accuracy: 0.5010 - val_loss: 0.6987 - val_accuracy: 0.4993\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.5011\n",
      "Epoch 2: val_loss improved from 0.69870 to 0.69670, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.6979 - accuracy: 0.5011 - val_loss: 0.6967 - val_accuracy: 0.4994\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5019\n",
      "Epoch 3: val_loss improved from 0.69670 to 0.69524, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.6960 - accuracy: 0.5019 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.4992\n",
      "Epoch 4: val_loss improved from 0.69524 to 0.69466, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.6952 - accuracy: 0.4992 - val_loss: 0.6947 - val_accuracy: 0.5047\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5103\n",
      "Epoch 5: val_loss improved from 0.69466 to 0.69418, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.6944 - accuracy: 0.5103 - val_loss: 0.6942 - val_accuracy: 0.5178\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5134\n",
      "Epoch 6: val_loss did not improve from 0.69418\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.6944 - accuracy: 0.5134 - val_loss: 0.6945 - val_accuracy: 0.5064\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5186\n",
      "Epoch 7: val_loss improved from 0.69418 to 0.69355, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.6941 - accuracy: 0.5186 - val_loss: 0.6935 - val_accuracy: 0.5254\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5242\n",
      "Epoch 8: val_loss did not improve from 0.69355\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.6937 - accuracy: 0.5242 - val_loss: 0.6942 - val_accuracy: 0.5112\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5281\n",
      "Epoch 9: val_loss improved from 0.69355 to 0.69326, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.6935 - accuracy: 0.5281 - val_loss: 0.6933 - val_accuracy: 0.5336\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5431\n",
      "Epoch 10: val_loss improved from 0.69326 to 0.69268, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.6929 - accuracy: 0.5431 - val_loss: 0.6927 - val_accuracy: 0.5452\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5468\n",
      "Epoch 11: val_loss improved from 0.69268 to 0.69213, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 160ms/step - loss: 0.6927 - accuracy: 0.5468 - val_loss: 0.6921 - val_accuracy: 0.5593\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5556\n",
      "Epoch 12: val_loss did not improve from 0.69213\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.6922 - accuracy: 0.5556 - val_loss: 0.6921 - val_accuracy: 0.5501\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5191\n",
      "Epoch 13: val_loss did not improve from 0.69213\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.6926 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5226\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5248\n",
      "Epoch 14: val_loss improved from 0.69213 to 0.69122, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.6923 - accuracy: 0.5248 - val_loss: 0.6912 - val_accuracy: 0.5505\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.5453\n",
      "Epoch 15: val_loss improved from 0.69122 to 0.69015, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.6910 - accuracy: 0.5453 - val_loss: 0.6901 - val_accuracy: 0.5119\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5235\n",
      "Epoch 16: val_loss improved from 0.69015 to 0.68927, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 154ms/step - loss: 0.6917 - accuracy: 0.5235 - val_loss: 0.6893 - val_accuracy: 0.5758\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5732\n",
      "Epoch 17: val_loss did not improve from 0.68927\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.6895 - accuracy: 0.5732 - val_loss: 0.6893 - val_accuracy: 0.5712\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.5690\n",
      "Epoch 18: val_loss did not improve from 0.68927\n",
      "19/19 [==============================] - 3s 156ms/step - loss: 0.6891 - accuracy: 0.5690 - val_loss: 0.6938 - val_accuracy: 0.5084\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.5697\n",
      "Epoch 19: val_loss improved from 0.68927 to 0.68643, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.6882 - accuracy: 0.5697 - val_loss: 0.6864 - val_accuracy: 0.5798\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.5940\n",
      "Epoch 20: val_loss improved from 0.68643 to 0.68194, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.6836 - accuracy: 0.5940 - val_loss: 0.6819 - val_accuracy: 0.5929\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6755 - accuracy: 0.6156\n",
      "Epoch 21: val_loss improved from 0.68194 to 0.66388, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.6755 - accuracy: 0.6156 - val_loss: 0.6639 - val_accuracy: 0.6337\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.6378\n",
      "Epoch 22: val_loss improved from 0.66388 to 0.64047, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 155ms/step - loss: 0.6514 - accuracy: 0.6378 - val_loss: 0.6405 - val_accuracy: 0.6671\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.6609\n",
      "Epoch 23: val_loss improved from 0.64047 to 0.62443, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.6436 - accuracy: 0.6609 - val_loss: 0.6244 - val_accuracy: 0.6946\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7062\n",
      "Epoch 24: val_loss improved from 0.62443 to 0.58591, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.6129 - accuracy: 0.7062 - val_loss: 0.5859 - val_accuracy: 0.7316\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5816 - accuracy: 0.7330\n",
      "Epoch 25: val_loss improved from 0.58591 to 0.57556, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5816 - accuracy: 0.7330 - val_loss: 0.5756 - val_accuracy: 0.7504\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.7360\n",
      "Epoch 26: val_loss improved from 0.57556 to 0.54629, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5708 - accuracy: 0.7360 - val_loss: 0.5463 - val_accuracy: 0.7631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.7684\n",
      "Epoch 27: val_loss improved from 0.54629 to 0.51946, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5387 - accuracy: 0.7684 - val_loss: 0.5195 - val_accuracy: 0.7737\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.7732\n",
      "Epoch 28: val_loss improved from 0.51946 to 0.50833, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5169 - accuracy: 0.7732 - val_loss: 0.5083 - val_accuracy: 0.7845\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.7799\n",
      "Epoch 29: val_loss did not improve from 0.50833\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.5074 - accuracy: 0.7799 - val_loss: 0.5205 - val_accuracy: 0.7622\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.7707\n",
      "Epoch 30: val_loss improved from 0.50833 to 0.48527, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5166 - accuracy: 0.7707 - val_loss: 0.4853 - val_accuracy: 0.7978\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.7768\n",
      "Epoch 31: val_loss improved from 0.48527 to 0.48440, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5092 - accuracy: 0.7768 - val_loss: 0.4844 - val_accuracy: 0.7965\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.7909\n",
      "Epoch 32: val_loss improved from 0.48440 to 0.48359, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4875 - accuracy: 0.7909 - val_loss: 0.4836 - val_accuracy: 0.7948\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.7692\n",
      "Epoch 33: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5199 - accuracy: 0.7692 - val_loss: 0.5068 - val_accuracy: 0.7699\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.6491\n",
      "Epoch 34: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.6709 - accuracy: 0.6491 - val_loss: 0.6813 - val_accuracy: 0.5830\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.7190\n",
      "Epoch 35: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5728 - accuracy: 0.7190 - val_loss: 0.5079 - val_accuracy: 0.7967\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.6999\n",
      "Epoch 36: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 155ms/step - loss: 0.5876 - accuracy: 0.6999 - val_loss: 0.5513 - val_accuracy: 0.7451\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.7065\n",
      "Epoch 37: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5807 - accuracy: 0.7065 - val_loss: 0.6599 - val_accuracy: 0.6073\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.6532\n",
      "Epoch 38: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 154ms/step - loss: 0.6563 - accuracy: 0.6532 - val_loss: 0.5091 - val_accuracy: 0.7990\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.7551\n",
      "Epoch 39: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.5396 - accuracy: 0.7551 - val_loss: 0.6158 - val_accuracy: 0.6411\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.7267\n",
      "Epoch 40: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5575 - accuracy: 0.7267 - val_loss: 0.5901 - val_accuracy: 0.6724\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.7346\n",
      "Epoch 41: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5527 - accuracy: 0.7346 - val_loss: 0.5605 - val_accuracy: 0.7404\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7413\n",
      "Epoch 42: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5432 - accuracy: 0.7413 - val_loss: 0.5193 - val_accuracy: 0.7595\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.6826\n",
      "Epoch 43: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.6144 - accuracy: 0.6826 - val_loss: 0.5162 - val_accuracy: 0.7940\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7164\n",
      "Epoch 44: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.5782 - accuracy: 0.7164 - val_loss: 0.5217 - val_accuracy: 0.7900\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.7016\n",
      "Epoch 45: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.5978 - accuracy: 0.7016 - val_loss: 0.5109 - val_accuracy: 0.7975\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.7405\n",
      "Epoch 46: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5505 - accuracy: 0.7405 - val_loss: 0.5320 - val_accuracy: 0.7427\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7254\n",
      "Epoch 47: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5692 - accuracy: 0.7254 - val_loss: 0.5686 - val_accuracy: 0.7414\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.6994\n",
      "Epoch 48: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5901 - accuracy: 0.6994 - val_loss: 0.5613 - val_accuracy: 0.7445\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.6998\n",
      "Epoch 49: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5947 - accuracy: 0.6998 - val_loss: 0.5137 - val_accuracy: 0.7857\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7226\n",
      "Epoch 50: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5645 - accuracy: 0.7226 - val_loss: 0.5138 - val_accuracy: 0.7858\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.6960\n",
      "Epoch 51: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.6022 - accuracy: 0.6960 - val_loss: 0.5070 - val_accuracy: 0.7927\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.7342\n",
      "Epoch 52: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 153ms/step - loss: 0.5642 - accuracy: 0.7342 - val_loss: 0.6562 - val_accuracy: 0.6104\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.7187\n",
      "Epoch 53: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5728 - accuracy: 0.7187 - val_loss: 0.7367 - val_accuracy: 0.5527\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.7188\n",
      "Epoch 54: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5730 - accuracy: 0.7188 - val_loss: 0.5185 - val_accuracy: 0.7609\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.7296\n",
      "Epoch 55: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 153ms/step - loss: 0.5611 - accuracy: 0.7296 - val_loss: 0.5387 - val_accuracy: 0.7426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.7448\n",
      "Epoch 56: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.5422 - accuracy: 0.7448 - val_loss: 0.5761 - val_accuracy: 0.7261\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7294\n",
      "Epoch 57: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.5616 - accuracy: 0.7294 - val_loss: 0.5134 - val_accuracy: 0.7686\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.7440\n",
      "Epoch 58: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.5434 - accuracy: 0.7440 - val_loss: 0.5127 - val_accuracy: 0.7692\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.7622\n",
      "Epoch 59: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5245 - accuracy: 0.7622 - val_loss: 0.5800 - val_accuracy: 0.7071\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5844 - accuracy: 0.7125\n",
      "Epoch 60: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5844 - accuracy: 0.7125 - val_loss: 0.5397 - val_accuracy: 0.7387\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.7502\n",
      "Epoch 61: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.5359 - accuracy: 0.7502 - val_loss: 0.5356 - val_accuracy: 0.7445\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.7540\n",
      "Epoch 62: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5326 - accuracy: 0.7540 - val_loss: 0.5228 - val_accuracy: 0.7573\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5401 - accuracy: 0.7467\n",
      "Epoch 63: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5401 - accuracy: 0.7467 - val_loss: 0.5602 - val_accuracy: 0.7439\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.7549\n",
      "Epoch 64: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5318 - accuracy: 0.7549 - val_loss: 0.5424 - val_accuracy: 0.7580\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7422\n",
      "Epoch 65: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5446 - accuracy: 0.7422 - val_loss: 0.5423 - val_accuracy: 0.7582\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.7549\n",
      "Epoch 66: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.5275 - accuracy: 0.7549 - val_loss: 0.5459 - val_accuracy: 0.7549\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.7657\n",
      "Epoch 67: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5156 - accuracy: 0.7657 - val_loss: 0.4930 - val_accuracy: 0.7838\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.7677\n",
      "Epoch 68: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5127 - accuracy: 0.7677 - val_loss: 0.6114 - val_accuracy: 0.7000\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.7743\n",
      "Epoch 69: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5058 - accuracy: 0.7743 - val_loss: 0.6165 - val_accuracy: 0.6753\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.7329\n",
      "Epoch 70: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5570 - accuracy: 0.7329 - val_loss: 0.6410 - val_accuracy: 0.6499\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5105 - accuracy: 0.7679\n",
      "Epoch 71: val_loss did not improve from 0.48359\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5105 - accuracy: 0.7679 - val_loss: 0.4964 - val_accuracy: 0.7783\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.7734\n",
      "Epoch 72: val_loss improved from 0.48359 to 0.48052, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5067 - accuracy: 0.7734 - val_loss: 0.4805 - val_accuracy: 0.7940\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.7856\n",
      "Epoch 73: val_loss improved from 0.48052 to 0.47647, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4925 - accuracy: 0.7856 - val_loss: 0.4765 - val_accuracy: 0.8033\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.7834\n",
      "Epoch 74: val_loss improved from 0.47647 to 0.47322, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4974 - accuracy: 0.7834 - val_loss: 0.4732 - val_accuracy: 0.8034\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.7776\n",
      "Epoch 75: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5033 - accuracy: 0.7776 - val_loss: 0.4744 - val_accuracy: 0.8032\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.7803\n",
      "Epoch 76: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5004 - accuracy: 0.7803 - val_loss: 0.4750 - val_accuracy: 0.8027\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.7801\n",
      "Epoch 77: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5004 - accuracy: 0.7801 - val_loss: 0.4750 - val_accuracy: 0.8038\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.7813\n",
      "Epoch 78: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4993 - accuracy: 0.7813 - val_loss: 0.5849 - val_accuracy: 0.7026\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.7704\n",
      "Epoch 79: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.5110 - accuracy: 0.7704 - val_loss: 0.4741 - val_accuracy: 0.8033\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4931 - accuracy: 0.7873\n",
      "Epoch 80: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4931 - accuracy: 0.7873 - val_loss: 0.5917 - val_accuracy: 0.6966\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.7806\n",
      "Epoch 81: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5010 - accuracy: 0.7806 - val_loss: 0.5263 - val_accuracy: 0.7506\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7839\n",
      "Epoch 82: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.4937 - accuracy: 0.7839 - val_loss: 0.4739 - val_accuracy: 0.8051\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.7928\n",
      "Epoch 83: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 153ms/step - loss: 0.4863 - accuracy: 0.7928 - val_loss: 0.5014 - val_accuracy: 0.7746\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.7921\n",
      "Epoch 84: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 156ms/step - loss: 0.4853 - accuracy: 0.7921 - val_loss: 0.4896 - val_accuracy: 0.7846\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.7925\n",
      "Epoch 85: val_loss did not improve from 0.47322\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4837 - accuracy: 0.7925 - val_loss: 0.4808 - val_accuracy: 0.8003\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7950\n",
      "Epoch 86: val_loss improved from 0.47322 to 0.46079, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.4800 - accuracy: 0.7950 - val_loss: 0.4608 - val_accuracy: 0.8078\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8016\n",
      "Epoch 87: val_loss improved from 0.46079 to 0.45842, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.4710 - accuracy: 0.8016 - val_loss: 0.4584 - val_accuracy: 0.8093\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.8041\n",
      "Epoch 88: val_loss did not improve from 0.45842\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4663 - accuracy: 0.8041 - val_loss: 0.4672 - val_accuracy: 0.8118\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8075\n",
      "Epoch 89: val_loss did not improve from 0.45842\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4628 - accuracy: 0.8075 - val_loss: 0.4586 - val_accuracy: 0.8075\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.8090\n",
      "Epoch 90: val_loss improved from 0.45842 to 0.45593, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4584 - accuracy: 0.8090 - val_loss: 0.4559 - val_accuracy: 0.8084\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4581 - accuracy: 0.8087\n",
      "Epoch 91: val_loss did not improve from 0.45593\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.4581 - accuracy: 0.8087 - val_loss: 0.4604 - val_accuracy: 0.8135\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8092\n",
      "Epoch 92: val_loss improved from 0.45593 to 0.45301, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.4579 - accuracy: 0.8092 - val_loss: 0.4530 - val_accuracy: 0.8094\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7887\n",
      "Epoch 93: val_loss improved from 0.45301 to 0.45111, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.4893 - accuracy: 0.7887 - val_loss: 0.4511 - val_accuracy: 0.8168\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.7936\n",
      "Epoch 94: val_loss did not improve from 0.45111\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.4808 - accuracy: 0.7936 - val_loss: 0.7107 - val_accuracy: 0.6299\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.7701\n",
      "Epoch 95: val_loss did not improve from 0.45111\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5155 - accuracy: 0.7701 - val_loss: 0.4557 - val_accuracy: 0.8057\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.7932\n",
      "Epoch 96: val_loss improved from 0.45111 to 0.45037, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.4799 - accuracy: 0.7932 - val_loss: 0.4504 - val_accuracy: 0.8171\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.7854\n",
      "Epoch 97: val_loss did not improve from 0.45037\n",
      "19/19 [==============================] - 3s 160ms/step - loss: 0.4924 - accuracy: 0.7854 - val_loss: 0.4616 - val_accuracy: 0.7992\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.7928\n",
      "Epoch 98: val_loss improved from 0.45037 to 0.44743, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 152ms/step - loss: 0.4808 - accuracy: 0.7928 - val_loss: 0.4474 - val_accuracy: 0.8152\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.7907\n",
      "Epoch 99: val_loss did not improve from 0.44743\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.4822 - accuracy: 0.7907 - val_loss: 0.6675 - val_accuracy: 0.6521\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.7841\n",
      "Epoch 100: val_loss did not improve from 0.44743\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.4922 - accuracy: 0.7841 - val_loss: 0.4482 - val_accuracy: 0.8178\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.7751\n",
      "Epoch 101: val_loss improved from 0.44743 to 0.44674, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5044 - accuracy: 0.7751 - val_loss: 0.4467 - val_accuracy: 0.8177\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.7992\n",
      "Epoch 102: val_loss improved from 0.44674 to 0.44647, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4711 - accuracy: 0.7992 - val_loss: 0.4465 - val_accuracy: 0.8151\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.8032\n",
      "Epoch 103: val_loss did not improve from 0.44647\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.4640 - accuracy: 0.8032 - val_loss: 0.5885 - val_accuracy: 0.7073\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.7987\n",
      "Epoch 104: val_loss improved from 0.44647 to 0.44604, saving model to qgru_training\\toptag_model_qgru.h5\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.4705 - accuracy: 0.7987 - val_loss: 0.4460 - val_accuracy: 0.8166\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.7945\n",
      "Epoch 105: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4769 - accuracy: 0.7945 - val_loss: 0.4587 - val_accuracy: 0.8129\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.7824\n",
      "Epoch 106: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.4958 - accuracy: 0.7824 - val_loss: 0.4604 - val_accuracy: 0.7994\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.8000\n",
      "Epoch 107: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.4689 - accuracy: 0.8000 - val_loss: 0.4472 - val_accuracy: 0.8183\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.7888\n",
      "Epoch 108: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4857 - accuracy: 0.7888 - val_loss: 0.4476 - val_accuracy: 0.8189\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.7897\n",
      "Epoch 109: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4851 - accuracy: 0.7897 - val_loss: 0.4539 - val_accuracy: 0.8137\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.7852\n",
      "Epoch 110: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 157ms/step - loss: 0.4908 - accuracy: 0.7852 - val_loss: 0.4750 - val_accuracy: 0.8010\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.7720\n",
      "Epoch 111: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5092 - accuracy: 0.7720 - val_loss: 0.4712 - val_accuracy: 0.8015\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.7518\n",
      "Epoch 112: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5383 - accuracy: 0.7518 - val_loss: 0.4609 - val_accuracy: 0.8070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.7854\n",
      "Epoch 113: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4867 - accuracy: 0.7854 - val_loss: 0.6932 - val_accuracy: 0.6177\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.7159\n",
      "Epoch 114: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5749 - accuracy: 0.7159 - val_loss: 0.5761 - val_accuracy: 0.6967\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.7726\n",
      "Epoch 115: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5037 - accuracy: 0.7726 - val_loss: 0.4667 - val_accuracy: 0.8058\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.7663\n",
      "Epoch 116: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 155ms/step - loss: 0.5133 - accuracy: 0.7663 - val_loss: 0.5755 - val_accuracy: 0.7110\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.7534\n",
      "Epoch 117: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.5305 - accuracy: 0.7534 - val_loss: 0.6267 - val_accuracy: 0.6612\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.7511\n",
      "Epoch 118: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5292 - accuracy: 0.7511 - val_loss: 0.4866 - val_accuracy: 0.7916\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.7531\n",
      "Epoch 119: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5281 - accuracy: 0.7531 - val_loss: 0.4847 - val_accuracy: 0.7882\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.7526\n",
      "Epoch 120: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.5244 - accuracy: 0.7526 - val_loss: 0.4812 - val_accuracy: 0.7916\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.7723\n",
      "Epoch 121: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.5090 - accuracy: 0.7723 - val_loss: 0.4820 - val_accuracy: 0.7914\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.7631\n",
      "Epoch 122: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.5203 - accuracy: 0.7631 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4982 - accuracy: 0.7761\n",
      "Epoch 123: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4982 - accuracy: 0.7761 - val_loss: 0.4665 - val_accuracy: 0.7993\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.7797\n",
      "Epoch 124: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4918 - accuracy: 0.7797 - val_loss: 0.4819 - val_accuracy: 0.7908\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7819\n",
      "Epoch 125: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.4905 - accuracy: 0.7819 - val_loss: 0.4627 - val_accuracy: 0.8023\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.7793\n",
      "Epoch 126: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4925 - accuracy: 0.7793 - val_loss: 0.4657 - val_accuracy: 0.8005\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.7818\n",
      "Epoch 127: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4922 - accuracy: 0.7818 - val_loss: 0.5644 - val_accuracy: 0.7163\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7806\n",
      "Epoch 128: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 153ms/step - loss: 0.4905 - accuracy: 0.7806 - val_loss: 0.5105 - val_accuracy: 0.7663\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.7789\n",
      "Epoch 129: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.4938 - accuracy: 0.7789 - val_loss: 0.4691 - val_accuracy: 0.7994\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.7609\n",
      "Epoch 130: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.5228 - accuracy: 0.7609 - val_loss: 0.4632 - val_accuracy: 0.8009\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.7917\n",
      "Epoch 131: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.4785 - accuracy: 0.7917 - val_loss: 0.4634 - val_accuracy: 0.8015\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7706\n",
      "Epoch 132: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5084 - accuracy: 0.7706 - val_loss: 0.4635 - val_accuracy: 0.8014\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.7810\n",
      "Epoch 133: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.4903 - accuracy: 0.7810 - val_loss: 0.4612 - val_accuracy: 0.8032\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.7763\n",
      "Epoch 134: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4990 - accuracy: 0.7763 - val_loss: 0.6490 - val_accuracy: 0.6637\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7700\n",
      "Epoch 135: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 153ms/step - loss: 0.5084 - accuracy: 0.7700 - val_loss: 0.4559 - val_accuracy: 0.8075\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.7851\n",
      "Epoch 136: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.4870 - accuracy: 0.7851 - val_loss: 0.5170 - val_accuracy: 0.7619\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.7960\n",
      "Epoch 137: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 152ms/step - loss: 0.4739 - accuracy: 0.7960 - val_loss: 0.4572 - val_accuracy: 0.8059\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.7752\n",
      "Epoch 138: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.5029 - accuracy: 0.7752 - val_loss: 0.4607 - val_accuracy: 0.8032\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.7683\n",
      "Epoch 139: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 154ms/step - loss: 0.5078 - accuracy: 0.7683 - val_loss: 0.4568 - val_accuracy: 0.8067\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7801\n",
      "Epoch 140: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.4915 - accuracy: 0.7801 - val_loss: 0.4569 - val_accuracy: 0.8066\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.7844\n",
      "Epoch 141: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4892 - accuracy: 0.7844 - val_loss: 0.7894 - val_accuracy: 0.5742\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.7745\n",
      "Epoch 142: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.5036 - accuracy: 0.7745 - val_loss: 0.4559 - val_accuracy: 0.8078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.7870\n",
      "Epoch 143: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.4866 - accuracy: 0.7870 - val_loss: 0.6390 - val_accuracy: 0.6511\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7767\n",
      "Epoch 144: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.4991 - accuracy: 0.7767 - val_loss: 0.4619 - val_accuracy: 0.8014\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4933 - accuracy: 0.7817\n",
      "Epoch 145: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.4933 - accuracy: 0.7817 - val_loss: 0.4567 - val_accuracy: 0.8075\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.7610\n",
      "Epoch 146: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.5194 - accuracy: 0.7610 - val_loss: 0.4594 - val_accuracy: 0.8043\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.7907\n",
      "Epoch 147: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4812 - accuracy: 0.7907 - val_loss: 0.4568 - val_accuracy: 0.8066\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.7867\n",
      "Epoch 148: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.4858 - accuracy: 0.7867 - val_loss: 0.6795 - val_accuracy: 0.6506\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.7767\n",
      "Epoch 149: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.4999 - accuracy: 0.7767 - val_loss: 0.4545 - val_accuracy: 0.8100\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.7916\n",
      "Epoch 150: val_loss did not improve from 0.44604\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.4806 - accuracy: 0.7916 - val_loss: 0.4543 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=20)\n",
    "adam = Adam(lr = 0.0002)\n",
    "toy_qgru_qat.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = toy_qgru_qat.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 2**14,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint('qgru_training/toptag_model_qgru.h5', verbose=1, save_best_only=True)],\n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451d248",
   "metadata": {},
   "source": [
    "Check the **AUC score** and **weight** after your training porcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13fbfa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 38s 62ms/step\n",
      "auc score for toy QGRU model is  0.872603187541387\n"
     ]
    }
   ],
   "source": [
    "y_keras = toy_qgru_qat.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(\"auc score for toy QGRU model is \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07fdaa7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer1': {'weights': [array([[-0.1875  , -0.125   , -0.21875 , -0.375   ,  0.34375 , -0.0625  ,\n",
       "           -0.34375 ,  0.25    ,  0.3125  ,  0.1875  , -0.0625  , -0.375   ,\n",
       "           -0.375   , -0.125   ,  0.40625 ],\n",
       "          [-0.625   , -0.5625  , -0.15625 , -0.4375  ,  0.28125 ,  0.1875  ,\n",
       "            0.625   ,  0.0625  ,  0.34375 , -0.328125,  0.375   ,  0.125   ,\n",
       "            0.25    , -0.4375  ,  0.8125  ],\n",
       "          [-0.3125  , -0.96875 , -0.0625  ,  0.15625 ,  0.03125 ,  0.71875 ,\n",
       "            0.21875 , -0.46875 ,  0.3125  , -0.140625,  1.0625  ,  0.125   ,\n",
       "            0.      ,  0.9375  , -0.78125 ],\n",
       "          [-0.0625  , -0.25    ,  0.1875  , -0.46875 ,  0.84375 , -0.15625 ,\n",
       "           -0.3125  , -0.1875  ,  0.3125  ,  0.1875  , -0.3125  ,  0.375   ,\n",
       "           -0.125   ,  0.0625  ,  0.1875  ],\n",
       "          [ 0.1875  ,  0.      , -0.96875 , -0.0625  , -0.3125  , -0.0625  ,\n",
       "           -0.96875 ,  0.96875 ,  0.96875 ,  0.484375, -1.9375  , -1.9375  ,\n",
       "           -2.75    , -1.5     ,  0.78125 ],\n",
       "          [-0.78125 , -0.59375 ,  0.21875 , -0.71875 , -0.25    ,  0.03125 ,\n",
       "            0.625   ,  0.34375 ,  0.46875 ,  0.40625 , -0.1875  ,  0.0625  ,\n",
       "           -0.125   ,  0.1875  ,  0.1875  ]], dtype=float32),\n",
       "   array([[-1.375    , -0.40625  , -0.78125  , -0.46875  , -0.96875  ,\n",
       "           -0.25     ,  0.453125 , -0.1953125, -0.359375 , -0.21875  ,\n",
       "            0.390625 ,  0.6875   ,  0.03125  ,  0.40625  , -0.171875 ],\n",
       "          [-0.75     , -0.5      ,  0.15625  , -0.625    , -0.53125  ,\n",
       "           -0.3125   ,  0.140625 ,  0.0625   , -0.140625 ,  0.140625 ,\n",
       "            0.484375 ,  0.28125  ,  0.484375 , -0.03125  , -0.328125 ],\n",
       "          [ 0.6875   ,  0.875    ,  0.96875  ,  0.15625  ,  0.90625  ,\n",
       "           -0.484375 , -0.28125  , -0.2421875, -0.484375 , -0.40625  ,\n",
       "            0.28125  ,  0.46875  ,  0.109375 ,  0.75     , -0.03125  ],\n",
       "          [-1.1875   ,  0.21875  , -0.1875   , -0.96875  , -0.96875  ,\n",
       "           -0.21875  ,  0.484375 , -0.2421875, -0.484375 , -0.0625   ,\n",
       "            0.140625 ,  0.28125  ,  0.328125 ,  0.40625  , -0.484375 ],\n",
       "          [-0.8125   , -0.96875  , -0.40625  , -0.59375  , -0.5      ,\n",
       "           -0.203125 ,  0.328125 , -0.171875 ,  0.484375 , -0.015625 ,\n",
       "           -0.015625 , -0.0625   , -0.265625 , -0.25     ,  0.03125  ]],\n",
       "         dtype=float32),\n",
       "   array([[-0.5  , -0.5  , -0.375, -0.5  , -0.125,  0.375,  0.25 ,  0.   ,\n",
       "            0.375,  0.125, -0.125, -0.125, -0.125, -0.125,  0.125],\n",
       "          [-0.5  , -0.5  , -0.375, -0.5  , -0.125,  0.375,  0.25 ,  0.   ,\n",
       "            0.375,  0.125, -0.125, -0.125, -0.125, -0.125,  0.25 ]],\n",
       "         dtype=float32)]},\n",
       " 'layer2': {'weights': [array([[ 0.78125 , -0.234375, -0.96875 ,  0.65625 , -0.484375],\n",
       "          [-0.03125 ,  0.09375 , -0.03125 ,  0.59375 ,  0.0625  ],\n",
       "          [-0.09375 ,  0.484375, -0.40625 ,  0.53125 , -0.21875 ],\n",
       "          [ 0.03125 ,  0.03125 , -0.5625  ,  0.96875 ,  0.25    ],\n",
       "          [-0.46875 ,  0.125   ,  0.84375 , -0.0625  , -0.390625]],\n",
       "         dtype=float32),\n",
       "   array([ 0.125, -0.125,  0.   ,  0.   , -0.25 ], dtype=float32)]},\n",
       " 'layer4': {'weights': [array([[-0.3125],\n",
       "          [ 0.3125],\n",
       "          [ 0.6875],\n",
       "          [-1.4375],\n",
       "          [ 0.375 ]], dtype=float32),\n",
       "   array([-0.125], dtype=float32)]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_quantized_weights(toy_qgru_qat, \"qat2int3fra_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f074bd3",
   "metadata": {},
   "source": [
    "From the training result we can see that we successfully quantized our model and the AUC score is better compares to post-training quantization result with same quantized bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db3555",
   "metadata": {},
   "source": [
    "### 3.4: Now is your time to do Quantization aware training to a similiar model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464864e8",
   "metadata": {},
   "source": [
    "The model we are using is the toptag model with one **LSTM** layer  we used in **Section 2.3**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572570b",
   "metadata": {},
   "source": [
    "Here you can see what the model looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38b2f514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (LSTM)               (None, 5)                 240       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 5)                 30        \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 5)                 0         \n",
      "                                                                 \n",
      " layer5 (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "toy_lstm = Sequential()\n",
    "toy_lstm.add(LSTM(5, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "               name = 'layer1', input_shape = (20,6)))\n",
    "toy_lstm.add(Dense(5, kernel_initializer='glorot_normal', name='layer3'))\n",
    "toy_lstm.add(Activation('relu', name = 'relu_0'))\n",
    "toy_lstm.add(Dense(1, name = 'layer5'))\n",
    "toy_lstm.add(Activation('sigmoid', name = 'output_sigmoid'))\n",
    "\n",
    "toy_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4095e7c",
   "metadata": {},
   "source": [
    "We also need to load the **training and testing data** since we need to trian our model this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ffd4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./x_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "y_train = y_train[:,4:5]\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb63be6",
   "metadata": {},
   "source": [
    "Write the **\"config\"** for applying quantization to our model\n",
    "<br>\n",
    "Here we also want to quantize this model to **3 fractional bits, 2 integer bits, 1 sign bits (6 bits in total)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_bits = 3\n",
    "int_bits = 2\n",
    "total_bits = frac_bits + int_bits + 1\n",
    "config = {\n",
    "    # give quantize-paramter to LSTM layer\n",
    "    \"QLSTM\":{\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "    },\n",
    "    # give quantize-paramter to all two Dense layers\n",
    "    \"QDense\":{\n",
    "        # Replace this line with your own code\n",
    "        # Replace this line with your own code\n",
    "    },\n",
    "    # give quantizate-paramter to the relu Activation layer\n",
    "    \"relu_0\" : # Replace this line with your own code\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b721328",
   "metadata": {},
   "source": [
    "Use the **\"model_quantize()\"** function to quantize our toptag model with lstm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_qlstm_qat = model_quantize(#the keras model we want to quantize,\n",
    "                               #the config we want for our quantization,\n",
    "                               #the total number of bits we want to quantize,\n",
    "                               #whether you want transfer_weights to be true or false\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c70b0",
   "metadata": {},
   "source": [
    "Check layers in your quantized model to make sure your config is working properly (Already implemented, you just need to run this code for checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82feb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in toy_qlstm_qat.layers:\n",
    "            if hasattr(layer, \"recurrent_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal), \n",
    "                     \"recurrent:\", str(layer.recurrent_quantizer_internal), \"state:\", str(layer.state_quantizer_internal))\n",
    "            elif hasattr(layer, \"kernel_quantizer\"):\n",
    "                print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "            elif hasattr(layer, \"quantized_relu\"):\n",
    "                print(layer.name, \"quantized_relu:\", str(layer.quantizer))\n",
    "            else:\n",
    "                print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203896e",
   "metadata": {},
   "source": [
    "**Training** the quantized model (Hint: the training process is nearly identical to want we did in **Section 3.3**)\n",
    "<br>\n",
    "Save the model to 'qlstm_training/toptag_model_qlstm.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=20)\n",
    "adam = Adam(lr = 0.0002)\n",
    "## Replace this line with your own code\n",
    "## Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae67311",
   "metadata": {},
   "source": [
    "Check the **AUC score** for the quantized model (Hine: use roc_auc_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e2404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace this line with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff67fc5",
   "metadata": {},
   "source": [
    "Check the **weights** for our quantized model (Hint: use \"model_save_quantized_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace this line with your own code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
